{
    "pdf_info": [
        {
            "para_blocks": [
                {
                    "bbox": [
                        105,
                        214,
                        220,
                        240
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                105,
                                214,
                                220,
                                240
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        105,
                                        214,
                                        220,
                                        240
                                    ],
                                    "type": "text",
                                    "content": "Chapter 3"
                                }
                            ]
                        }
                    ],
                    "index": 0,
                    "level": 1
                },
                {
                    "bbox": [
                        104,
                        267,
                        423,
                        329
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                267,
                                423,
                                329
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        267,
                                        423,
                                        329
                                    ],
                                    "type": "text",
                                    "content": "Finite Markov Decision Processes"
                                }
                            ]
                        }
                    ],
                    "index": 1,
                    "level": 1
                },
                {
                    "bbox": [
                        104,
                        372,
                        530,
                        518
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                372,
                                530,
                                518
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        372,
                                        530,
                                        518
                                    ],
                                    "type": "text",
                                    "content": "In this chapter we introduce the formal problem of finite Markov decision processes, or finite MDPs, which we try to solve in the rest of the book. This problem involves evaluative feedback, as in bandits, but also an associative aspectâ€”choosing different actions in different situations. MDPs are a classical formalization of sequential decision making, where actions influence not just immediate rewards, but also subsequent situations, or states, and through those future rewards. Thus MDPs involve delayed reward and the need to trade off immediate and delayed reward. Whereas in bandit problems we estimated the value "
                                },
                                {
                                    "bbox": [
                                        104,
                                        372,
                                        530,
                                        518
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}(a)"
                                },
                                {
                                    "bbox": [
                                        104,
                                        372,
                                        530,
                                        518
                                    ],
                                    "type": "text",
                                    "content": " of each action "
                                },
                                {
                                    "bbox": [
                                        104,
                                        372,
                                        530,
                                        518
                                    ],
                                    "type": "inline_equation",
                                    "content": "a"
                                },
                                {
                                    "bbox": [
                                        104,
                                        372,
                                        530,
                                        518
                                    ],
                                    "type": "text",
                                    "content": ", in MDPs we estimate the value "
                                },
                                {
                                    "bbox": [
                                        104,
                                        372,
                                        530,
                                        518
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}(s,a)"
                                },
                                {
                                    "bbox": [
                                        104,
                                        372,
                                        530,
                                        518
                                    ],
                                    "type": "text",
                                    "content": " of each action "
                                },
                                {
                                    "bbox": [
                                        104,
                                        372,
                                        530,
                                        518
                                    ],
                                    "type": "inline_equation",
                                    "content": "a"
                                },
                                {
                                    "bbox": [
                                        104,
                                        372,
                                        530,
                                        518
                                    ],
                                    "type": "text",
                                    "content": " in each state "
                                },
                                {
                                    "bbox": [
                                        104,
                                        372,
                                        530,
                                        518
                                    ],
                                    "type": "inline_equation",
                                    "content": "s"
                                },
                                {
                                    "bbox": [
                                        104,
                                        372,
                                        530,
                                        518
                                    ],
                                    "type": "text",
                                    "content": ", or we estimate the value "
                                },
                                {
                                    "bbox": [
                                        104,
                                        372,
                                        530,
                                        518
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}(s)"
                                },
                                {
                                    "bbox": [
                                        104,
                                        372,
                                        530,
                                        518
                                    ],
                                    "type": "text",
                                    "content": " of each state given optimal action selections. These state- dependent quantities are essential to accurately assigning credit for long- term consequences to individual action selections."
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        104,
                        520,
                        529,
                        625
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                520,
                                529,
                                625
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        520,
                                        529,
                                        625
                                    ],
                                    "type": "text",
                                    "content": "MDPs are a mathematically idealized form of the reinforcement learning problem for which precise theoretical statements can be made. We introduce key elements of the problem's mathematical structure, such as returns, value functions, and Bellman equations. We try to convey the wide range of applications that can be formulated as finite MDPs. As in all of artificial intelligence, there is a tension between breadth of applicability and mathematical tractability. In this chapter we introduce this tension and discuss some of the trade- offs and challenges that it implies. Some ways in which reinforcement learning can be taken beyond MDPs are treated in Chapter 17."
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        104,
                        655,
                        415,
                        674
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                655,
                                415,
                                674
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        655,
                                        415,
                                        674
                                    ],
                                    "type": "text",
                                    "content": "3.1 The Agent-Environment Interface"
                                }
                            ]
                        }
                    ],
                    "index": 4,
                    "level": 1
                },
                {
                    "bbox": [
                        104,
                        687,
                        530,
                        740
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                687,
                                530,
                                740
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        687,
                                        530,
                                        740
                                    ],
                                    "type": "text",
                                    "content": "MDPs are meant to be a straightforward framing of the problem of learning from interaction to achieve a goal. The learner and decision maker is called the agent. The thing it interacts with, comprising everything outside the agent, is called the environment. These interact continually, the agent selecting actions and the environment responding to"
                                }
                            ]
                        }
                    ],
                    "index": 5
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 0
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        64,
                        140,
                        489,
                        180
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                140,
                                489,
                                180
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        140,
                                        489,
                                        180
                                    ],
                                    "type": "text",
                                    "content": "these actions and presenting new situations to the agent."
                                },
                                {
                                    "bbox": [
                                        64,
                                        140,
                                        489,
                                        180
                                    ],
                                    "type": "inline_equation",
                                    "content": "^{1}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        140,
                                        489,
                                        180
                                    ],
                                    "type": "text",
                                    "content": " The environment also gives rise to rewards, special numerical values that the agent seeks to maximize over time through its choice of actions."
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "type": "image",
                    "bbox": [
                        136,
                        193,
                        417,
                        294
                    ],
                    "blocks": [
                        {
                            "bbox": [
                                136,
                                193,
                                417,
                                294
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        136,
                                        193,
                                        417,
                                        294
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                136,
                                                193,
                                                417,
                                                294
                                            ],
                                            "type": "image",
                                            "image_path": "f633a19a1ed4b06391bdf2f779dfe5c216c9c0a52294777264ba3c63aab9631c.jpg"
                                        }
                                    ]
                                }
                            ],
                            "index": 1,
                            "type": "image_body"
                        },
                        {
                            "bbox": [
                                98,
                                298,
                                453,
                                311
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        98,
                                        298,
                                        453,
                                        311
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                98,
                                                298,
                                                453,
                                                311
                                            ],
                                            "type": "text",
                                            "content": "Figure 3.1: The agent-environment interaction in a Markov decision process."
                                        }
                                    ]
                                }
                            ],
                            "index": 2,
                            "type": "image_caption"
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        64,
                        326,
                        490,
                        406
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                326,
                                490,
                                406
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        326,
                                        490,
                                        406
                                    ],
                                    "type": "text",
                                    "content": "More specifically, the agent and environment interact at each of a sequence of discrete time steps, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        326,
                                        490,
                                        406
                                    ],
                                    "type": "inline_equation",
                                    "content": "t = 0,1,2,3,\\ldots"
                                },
                                {
                                    "bbox": [
                                        64,
                                        326,
                                        490,
                                        406
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\mathcal{Z}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        326,
                                        490,
                                        406
                                    ],
                                    "type": "text",
                                    "content": " At each time step "
                                },
                                {
                                    "bbox": [
                                        64,
                                        326,
                                        490,
                                        406
                                    ],
                                    "type": "inline_equation",
                                    "content": "t"
                                },
                                {
                                    "bbox": [
                                        64,
                                        326,
                                        490,
                                        406
                                    ],
                                    "type": "text",
                                    "content": " , the agent receives some representation of the environment's state, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        326,
                                        490,
                                        406
                                    ],
                                    "type": "inline_equation",
                                    "content": "S_{t}\\in \\mathcal{S}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        326,
                                        490,
                                        406
                                    ],
                                    "type": "text",
                                    "content": " , and on that basis selects an action, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        326,
                                        490,
                                        406
                                    ],
                                    "type": "inline_equation",
                                    "content": "A_{t}\\in \\mathcal{A}(s)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        326,
                                        490,
                                        406
                                    ],
                                    "type": "text",
                                    "content": " .3 One time step later, in part as a consequence of its action, the agent receives a numerical reward, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        326,
                                        490,
                                        406
                                    ],
                                    "type": "inline_equation",
                                    "content": "R_{t + 1}\\in \\mathcal{R}\\subset \\mathbb{R}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        326,
                                        490,
                                        406
                                    ],
                                    "type": "text",
                                    "content": " , and finds itself in a new state, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        326,
                                        490,
                                        406
                                    ],
                                    "type": "inline_equation",
                                    "content": "S_{t + 1}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        326,
                                        490,
                                        406
                                    ],
                                    "type": "text",
                                    "content": " .4 The MDP and agent together thereby give rise to a sequence or trajectory that begins like this:"
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        92,
                        417,
                        488,
                        431
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                92,
                                417,
                                488,
                                431
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        92,
                                        417,
                                        488,
                                        431
                                    ],
                                    "type": "interline_equation",
                                    "content": "S_{0},A_{0},R_{1},S_{1},A_{1},R_{2},S_{2},A_{2},R_{3},\\ldots \\tag{3.1}",
                                    "image_path": "5ea6389dc8b76ba6fe764de13e11ef81841c69f08296944d23ca0e37afd18ff9.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        64,
                        443,
                        489,
                        523
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                443,
                                489,
                                523
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        443,
                                        489,
                                        523
                                    ],
                                    "type": "text",
                                    "content": "In a finite MDP, the sets of states, actions, and rewards "
                                },
                                {
                                    "bbox": [
                                        64,
                                        443,
                                        489,
                                        523
                                    ],
                                    "type": "inline_equation",
                                    "content": "(\\mathcal{S},\\mathcal{A}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        443,
                                        489,
                                        523
                                    ],
                                    "type": "text",
                                    "content": " , and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        443,
                                        489,
                                        523
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\mathcal{R}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        443,
                                        489,
                                        523
                                    ],
                                    "type": "text",
                                    "content": " ) all have a finite number of elements. In this case, the random variables "
                                },
                                {
                                    "bbox": [
                                        64,
                                        443,
                                        489,
                                        523
                                    ],
                                    "type": "inline_equation",
                                    "content": "R_{t}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        443,
                                        489,
                                        523
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        443,
                                        489,
                                        523
                                    ],
                                    "type": "inline_equation",
                                    "content": "S_{t}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        443,
                                        489,
                                        523
                                    ],
                                    "type": "text",
                                    "content": " have well defined discrete probability distributions dependent only on the preceding state and action. That is, for particular values of these random variables, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        443,
                                        489,
                                        523
                                    ],
                                    "type": "inline_equation",
                                    "content": "s^{\\prime}\\in \\mathcal{S}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        443,
                                        489,
                                        523
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        443,
                                        489,
                                        523
                                    ],
                                    "type": "inline_equation",
                                    "content": "r\\in \\mathcal{R}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        443,
                                        489,
                                        523
                                    ],
                                    "type": "text",
                                    "content": " , there is a probability of those values occurring at time "
                                },
                                {
                                    "bbox": [
                                        64,
                                        443,
                                        489,
                                        523
                                    ],
                                    "type": "inline_equation",
                                    "content": "t"
                                },
                                {
                                    "bbox": [
                                        64,
                                        443,
                                        489,
                                        523
                                    ],
                                    "type": "text",
                                    "content": " , given particular values of the preceding state and action:"
                                }
                            ]
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        91,
                        534,
                        488,
                        548
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                91,
                                534,
                                488,
                                548
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        91,
                                        534,
                                        488,
                                        548
                                    ],
                                    "type": "interline_equation",
                                    "content": "p(s^{\\prime},r|s,a) \\doteq \\operatorname *{Pr}\\{S_{t} = s^{\\prime},R_{t} = r\\mid S_{t - 1} = s,A_{t - 1} = a\\} , \\tag{3.2}",
                                    "image_path": "cb3a433d3583a4f305de45f6c757d287c57959acba66de4156da057ab3d748a7.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 6
                },
                {
                    "bbox": [
                        64,
                        559,
                        490,
                        627
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                559,
                                490,
                                627
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        559,
                                        490,
                                        627
                                    ],
                                    "type": "text",
                                    "content": "for all "
                                },
                                {
                                    "bbox": [
                                        64,
                                        559,
                                        490,
                                        627
                                    ],
                                    "type": "inline_equation",
                                    "content": "s^{\\prime},s\\in \\mathcal{S}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        559,
                                        490,
                                        627
                                    ],
                                    "type": "inline_equation",
                                    "content": "r\\in \\mathcal{R}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        559,
                                        490,
                                        627
                                    ],
                                    "type": "text",
                                    "content": " , and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        559,
                                        490,
                                        627
                                    ],
                                    "type": "inline_equation",
                                    "content": "a\\in \\mathcal{A}(s)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        559,
                                        490,
                                        627
                                    ],
                                    "type": "text",
                                    "content": " . The function "
                                },
                                {
                                    "bbox": [
                                        64,
                                        559,
                                        490,
                                        627
                                    ],
                                    "type": "inline_equation",
                                    "content": "p"
                                },
                                {
                                    "bbox": [
                                        64,
                                        559,
                                        490,
                                        627
                                    ],
                                    "type": "text",
                                    "content": " defines the dynamics of the MDP. The dot over the equals sign is the equation reminds us that it is a definition (in this case of the function "
                                },
                                {
                                    "bbox": [
                                        64,
                                        559,
                                        490,
                                        627
                                    ],
                                    "type": "inline_equation",
                                    "content": "p"
                                },
                                {
                                    "bbox": [
                                        64,
                                        559,
                                        490,
                                        627
                                    ],
                                    "type": "text",
                                    "content": " ) rather than a fact that follows from previous definitions. The dynamics function "
                                },
                                {
                                    "bbox": [
                                        64,
                                        559,
                                        490,
                                        627
                                    ],
                                    "type": "inline_equation",
                                    "content": "p:\\mathcal{S}\\times \\mathcal{R}\\times \\mathcal{S}\\times \\mathcal{A}\\rightarrow [0,1]"
                                },
                                {
                                    "bbox": [
                                        64,
                                        559,
                                        490,
                                        627
                                    ],
                                    "type": "text",
                                    "content": " is an ordinary deterministic function of four arguments. The "
                                },
                                {
                                    "bbox": [
                                        64,
                                        559,
                                        490,
                                        627
                                    ],
                                    "type": "inline_equation",
                                    "content": "^{\\ast}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        559,
                                        490,
                                        627
                                    ],
                                    "type": "text",
                                    "content": " in the middle of it comes from the notation for conditional probability,"
                                }
                            ]
                        }
                    ],
                    "index": 7
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 1
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        102,
                        140,
                        530,
                        168
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                102,
                                140,
                                530,
                                168
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        102,
                                        140,
                                        530,
                                        168
                                    ],
                                    "type": "text",
                                    "content": "but here it just reminds us that "
                                },
                                {
                                    "bbox": [
                                        102,
                                        140,
                                        530,
                                        168
                                    ],
                                    "type": "inline_equation",
                                    "content": "p"
                                },
                                {
                                    "bbox": [
                                        102,
                                        140,
                                        530,
                                        168
                                    ],
                                    "type": "text",
                                    "content": " specifies a probability distribution for each choice of "
                                },
                                {
                                    "bbox": [
                                        102,
                                        140,
                                        530,
                                        168
                                    ],
                                    "type": "inline_equation",
                                    "content": "s"
                                },
                                {
                                    "bbox": [
                                        102,
                                        140,
                                        530,
                                        168
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        102,
                                        140,
                                        530,
                                        168
                                    ],
                                    "type": "inline_equation",
                                    "content": "a"
                                },
                                {
                                    "bbox": [
                                        102,
                                        140,
                                        530,
                                        168
                                    ],
                                    "type": "text",
                                    "content": ", that is, that"
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        130,
                        176,
                        528,
                        204
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                130,
                                176,
                                528,
                                204
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        130,
                                        176,
                                        528,
                                        204
                                    ],
                                    "type": "interline_equation",
                                    "content": "\\sum_{s^{\\prime}\\in \\mathcal{S}}\\sum_{r\\in \\mathcal{R}}p(s^{\\prime},r|s,a) = 1,\\mathrm{~for~all~}s\\in \\mathcal{S},a\\in \\mathcal{A}(s). \\tag{3.3}",
                                    "image_path": "63f0e43d04baa36052f6edabb7e69651c926d7584f6746223ae7eee9cc2d0451.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        104,
                        213,
                        530,
                        346
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                213,
                                530,
                                346
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        213,
                                        530,
                                        346
                                    ],
                                    "type": "text",
                                    "content": "In a Markov decision process, the probabilities given by "
                                },
                                {
                                    "bbox": [
                                        104,
                                        213,
                                        530,
                                        346
                                    ],
                                    "type": "inline_equation",
                                    "content": "p"
                                },
                                {
                                    "bbox": [
                                        104,
                                        213,
                                        530,
                                        346
                                    ],
                                    "type": "text",
                                    "content": " completely characterize the environment's dynamics. That is, the probability of each possible value for "
                                },
                                {
                                    "bbox": [
                                        104,
                                        213,
                                        530,
                                        346
                                    ],
                                    "type": "inline_equation",
                                    "content": "S_{t}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        213,
                                        530,
                                        346
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        104,
                                        213,
                                        530,
                                        346
                                    ],
                                    "type": "inline_equation",
                                    "content": "R_{t}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        213,
                                        530,
                                        346
                                    ],
                                    "type": "text",
                                    "content": " depends on the immediately preceding state and action, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        213,
                                        530,
                                        346
                                    ],
                                    "type": "inline_equation",
                                    "content": "S_{t - 1}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        213,
                                        530,
                                        346
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        104,
                                        213,
                                        530,
                                        346
                                    ],
                                    "type": "inline_equation",
                                    "content": "A_{t - 1}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        213,
                                        530,
                                        346
                                    ],
                                    "type": "text",
                                    "content": ", and, given them, not at all on earlier states and actions. This is best viewed as a restriction not on the decision process, but on the state. The state must include information about all aspects of the past agent- environment interaction that make a difference for the future. If it does, then the state is said to have the Markov property. We will assume the Markov property throughout this book, though starting in Part II we will consider approximation methods that do not rely on it, and in Chapter 17 we consider how a Markov state can be efficiently learned and constructed from non- Markov observations."
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        104,
                        348,
                        530,
                        388
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                348,
                                530,
                                388
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        348,
                                        530,
                                        388
                                    ],
                                    "type": "text",
                                    "content": "From the four- argument dynamics function, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        348,
                                        530,
                                        388
                                    ],
                                    "type": "inline_equation",
                                    "content": "p"
                                },
                                {
                                    "bbox": [
                                        104,
                                        348,
                                        530,
                                        388
                                    ],
                                    "type": "text",
                                    "content": ", one can compute anything else one might want to know about the environment, such as the state- transition probabilities (which we denote, with a slight abuse of notation, as a three- argument function "
                                },
                                {
                                    "bbox": [
                                        104,
                                        348,
                                        530,
                                        388
                                    ],
                                    "type": "inline_equation",
                                    "content": "p: \\mathcal{S} \\times \\mathcal{S} \\times \\mathcal{A} \\to [0, 1]"
                                },
                                {
                                    "bbox": [
                                        104,
                                        348,
                                        530,
                                        388
                                    ],
                                    "type": "text",
                                    "content": "),"
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        130,
                        408,
                        528,
                        436
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                130,
                                408,
                                528,
                                436
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        130,
                                        408,
                                        528,
                                        436
                                    ],
                                    "type": "interline_equation",
                                    "content": "p(s^{\\prime}|s,a) \\doteq \\operatorname *{Pr}\\{S_{t} = s^{\\prime}\\mid S_{t - 1} = s,A_{t - 1} = a\\} = \\sum_{r\\in \\mathcal{R}}p(s^{\\prime},r|s,a). \\tag{3.4}",
                                    "image_path": "df781eafe7644083fdea7b58aaf728c809b36fc5f261cb5b08ad328a16012b87.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        102,
                        445,
                        530,
                        471
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                102,
                                445,
                                530,
                                471
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        102,
                                        445,
                                        530,
                                        471
                                    ],
                                    "type": "text",
                                    "content": "We can also compute the expected rewards for state- action pairs as a two- argument function "
                                },
                                {
                                    "bbox": [
                                        102,
                                        445,
                                        530,
                                        471
                                    ],
                                    "type": "inline_equation",
                                    "content": "r: \\mathcal{S} \\times \\mathcal{A} \\to \\mathbb{R}"
                                },
                                {
                                    "bbox": [
                                        102,
                                        445,
                                        530,
                                        471
                                    ],
                                    "type": "text",
                                    "content": ":"
                                }
                            ]
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        131,
                        479,
                        528,
                        507
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                131,
                                479,
                                528,
                                507
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        131,
                                        479,
                                        528,
                                        507
                                    ],
                                    "type": "interline_equation",
                                    "content": "r(s,a) \\doteq \\mathbb{E}[R_t \\mid S_{t - 1} = s, A_{t - 1} = a] = \\sum_{r \\in \\mathcal{R}} r \\sum_{s' \\in \\mathcal{S}} p(s', r|s,a), \\tag{3.5}",
                                    "image_path": "f1bb24b8b7679458d5a431f293649c143ad55aa7f02110ceff7ce8f508c62a5e.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 6
                },
                {
                    "bbox": [
                        102,
                        516,
                        530,
                        542
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                102,
                                516,
                                530,
                                542
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        102,
                                        516,
                                        530,
                                        542
                                    ],
                                    "type": "text",
                                    "content": "and the expected rewards for state- action- next- state triples as a three- argument function "
                                },
                                {
                                    "bbox": [
                                        102,
                                        516,
                                        530,
                                        542
                                    ],
                                    "type": "inline_equation",
                                    "content": "r: \\mathcal{S} \\times \\mathcal{A} \\times \\mathcal{S} \\to \\mathbb{R}"
                                },
                                {
                                    "bbox": [
                                        102,
                                        516,
                                        530,
                                        542
                                    ],
                                    "type": "text",
                                    "content": ","
                                }
                            ]
                        }
                    ],
                    "index": 7
                },
                {
                    "bbox": [
                        130,
                        549,
                        528,
                        584
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                130,
                                549,
                                528,
                                584
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        130,
                                        549,
                                        528,
                                        584
                                    ],
                                    "type": "interline_equation",
                                    "content": "r(s,a,s^{\\prime}) \\doteq \\mathbb{E}[R_t \\mid S_{t - 1} = s, A_{t - 1} = a, S_t = s^{\\prime}] = \\sum_{r \\in \\mathcal{R}} r \\frac{p(s^{\\prime}, r|s,a)}{p(s^{\\prime}|s,a)}. \\tag{3.6}",
                                    "image_path": "19640abacab5b2715a6d67d0c74bdfe4d7fb9221d63260b5202b10871ab685af.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 8
                },
                {
                    "bbox": [
                        102,
                        592,
                        530,
                        619
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                102,
                                592,
                                530,
                                619
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        102,
                                        592,
                                        530,
                                        619
                                    ],
                                    "type": "text",
                                    "content": "In this book, we usually use the four- argument "
                                },
                                {
                                    "bbox": [
                                        102,
                                        592,
                                        530,
                                        619
                                    ],
                                    "type": "inline_equation",
                                    "content": "p"
                                },
                                {
                                    "bbox": [
                                        102,
                                        592,
                                        530,
                                        619
                                    ],
                                    "type": "text",
                                    "content": " function (3.2), but each of these other notations are also occasionally convenient."
                                }
                            ]
                        }
                    ],
                    "index": 9
                },
                {
                    "bbox": [
                        104,
                        620,
                        530,
                        740
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                620,
                                530,
                                740
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        620,
                                        530,
                                        740
                                    ],
                                    "type": "text",
                                    "content": "The MDP framework is abstract and flexible and can be applied to many different problems in many different ways. For example, the time steps need not refer to fixed intervals of real time; they can refer to arbitrary successive stages of decision making and acting. The actions can be low- level controls, such as the voltages applied to the motors of a robot arm, or high- level decisions, such as whether or not to have lunch or to go to graduate school. Similarly, the states can take a wide variety of forms. They can be completely determined by low- level sensations, such as direct sensor readings, or they can be more high- level and abstract, such as symbolic descriptions of objects in a room. Some of what makes up a state could be based on memory of past sensations or"
                                }
                            ]
                        }
                    ],
                    "index": 10
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 2
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        64,
                        141,
                        490,
                        220
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                141,
                                490,
                                220
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        141,
                                        490,
                                        220
                                    ],
                                    "type": "text",
                                    "content": "even be entirely mental or subjective. For example, an agent could be in the state of not being sure where an object is, or of having just been surprised in some clearly defined sense. Similarly, some actions might be totally mental or computational. For example, some actions might control what an agent chooses to think about, or where it focuses its attention. In general, actions can be any decisions we want to learn how to make, and states can be anything we can know that might be useful in making them."
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        64,
                        222,
                        490,
                        328
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                222,
                                490,
                                328
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        222,
                                        490,
                                        328
                                    ],
                                    "type": "text",
                                    "content": "In particular, the boundary between agent and environment is typically not the same as the physical boundary of a robot's or an animal's body. Usually, the boundary is drawn closer to the agent than that. For example, the motors and mechanical linkages of a robot and its sensing hardware should usually be considered parts of the environment rather than parts of the agent. Similarly, if we apply the MDP framework to a person or animal, the muscles, skeleton, and sensory organs should be considered part of the environment. Rewards, too, presumably are computed inside the physical bodies of natural and artificial learning systems, but are considered external to the agent."
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        64,
                        329,
                        490,
                        475
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                329,
                                490,
                                475
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        329,
                                        490,
                                        475
                                    ],
                                    "type": "text",
                                    "content": "The general rule we follow is that anything that cannot be changed arbitrarily by the agent is considered to be outside of it and thus part of its environment. We do not assume that everything in the environment is unknown to the agent. For example, the agent often knows quite a bit about how its rewards are computed as a function of its actions and the states in which they are taken. But we always consider the reward computation to be external to the agent because it defines the task facing the agent and thus must be beyond its ability to change arbitrarily. In fact, in some cases the agent may know everything about how its environment works and still face a difficult reinforcement learning task, just as we may know exactly how a puzzle like Rubik's cube works, but still be unable to solve it. The agent- environment boundary represents the limit of the agent's absolute control, not of its knowledge."
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        64,
                        476,
                        490,
                        568
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                476,
                                490,
                                568
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        476,
                                        490,
                                        568
                                    ],
                                    "type": "text",
                                    "content": "The agent- environment boundary can be located at different places for different purposes. In a complicated robot, many different agents may be operating at once, each with its own boundary. For example, one agent may make high- level decisions which form part of the states faced by a lower- level agent that implements the high- level decisions. In practice, the agent- environment boundary is determined once one has selected particular states, actions, and rewards, and thus has identified a specific decision- making task of interest."
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        64,
                        570,
                        490,
                        689
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                570,
                                490,
                                689
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        689
                                    ],
                                    "type": "text",
                                    "content": "The MDP framework is a considerable abstraction of the problem of goal- directed learning from interaction. It proposes that whatever the details of the sensory, memory, and control apparatus, and whatever objective one is trying to achieve, any problem of learning goal- directed behavior can be reduced to three signals passing back and forth between an agent and its environment: one signal to represent the choices made by the agent (the actions), one signal to represent the basis on which the choices are made (the states), and one signal to define the agent's goal (the rewards). This framework may not be sufficient to represent all decision- learning problems usefully, but it has proved to be widely useful and applicable."
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        65,
                        690,
                        490,
                        730
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                65,
                                690,
                                490,
                                730
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        65,
                                        690,
                                        490,
                                        730
                                    ],
                                    "type": "text",
                                    "content": "Of course, the particular states and actions vary greatly from task to task, and how they are represented can strongly affect performance. In reinforcement learning, as in other kinds of learning, such representational choices are at present more art than science."
                                }
                            ]
                        }
                    ],
                    "index": 5
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 3
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        104,
                        141,
                        529,
                        180
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                141,
                                529,
                                180
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        529,
                                        180
                                    ],
                                    "type": "text",
                                    "content": "In this book we offer some advice and examples regarding good ways of representing states and actions, but our primary focus is on general principles for learning how to behave once the representations have been selected."
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        104,
                        190,
                        530,
                        362
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                190,
                                530,
                                362
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        190,
                                        530,
                                        362
                                    ],
                                    "type": "text",
                                    "content": "Example 3.1: Bioreactor Suppose reinforcement learning is being applied to determine moment- by- moment temperatures and stirring rates for a bioreactor (a large vat of nutrients and bacteria used to produce useful chemicals). The actions in such an application might be target temperatures and target stirring rates that are passed to lower- level control systems that, in turn, directly activate heating elements and motors to attain the targets. The states are likely to be thermocouple and other sensory readings, perhaps filtered and delayed, plus symbolic inputs representing the ingredients in the vat and the target chemical. The rewards might be moment- by- moment measures of the rate at which the useful chemical is produced by the bioreactor. Notice that here each state is a list, or vector, of sensor readings and symbolic inputs, and each action is a vector consisting of a target temperature and a stirring rate. It is typical of reinforcement learning tasks to have states and actions with such structured representations. Rewards, on the other hand, are always single numbers."
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        104,
                        373,
                        530,
                        492
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                373,
                                530,
                                492
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        373,
                                        530,
                                        492
                                    ],
                                    "type": "text",
                                    "content": "Example 3.2: Pick- and- Place Robot Consider using reinforcement learning to control the motion of a robot arm in a repetitive pick- and- place task. If we want to learn movements that are fast and smooth, the learning agent will have to control the motors directly and have low- latency information about the current positions and velocities of the mechanical linkages. The actions in this case might be the voltages applied to each motor at each joint, and the states might be the latest readings of joint angles and velocities. The reward might be +1 for each object successfully picked up and placed. To encourage smooth movements, on each time step a small, negative reward could be given as a function of the moment- to- moment jerkiness of the motion."
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        104,
                        502,
                        530,
                        555
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                502,
                                530,
                                555
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        502,
                                        530,
                                        555
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.1 Device three example tasks of your own that fit into the MDP framework, identifying for each its states, actions, and rewards. Make the three examples as different from each other as possible. The framework is abstract and flexible and can be applied in many different ways. Stretch its limits in some way in at least one of your examples."
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        104,
                        565,
                        529,
                        592
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                565,
                                529,
                                592
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        565,
                                        529,
                                        592
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.2 Is the MDP framework adequate to usefully represent all goal- directed learning tasks? Can you think of any clear exceptions?"
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        104,
                        602,
                        530,
                        722
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                602,
                                530,
                                722
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        602,
                                        530,
                                        722
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.3 Consider the problem of driving. You could define the actions in terms of the accelerator, steering wheel, and brake, that is, where your body meets the machine. Or you could define them farther outâ€”say, where the rubber meets the road, considering your actions to be tire torques. Or you could define them farther inâ€”say, where your brain meets your body, the actions being muscle twitches to control your limbs. Or you could go to a really high level and say that your actions are your choices of where to drive. What is the right level, the right place to draw the line between agent and environment? On what basis is one location of the line to be preferred over another? Is there any fundamental reason for preferring one location over another, or is it a free choice?"
                                }
                            ]
                        }
                    ],
                    "index": 5
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 4
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        77,
                        140,
                        254,
                        154
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                77,
                                140,
                                254,
                                154
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        77,
                                        140,
                                        254,
                                        154
                                    ],
                                    "type": "text",
                                    "content": "Example 3.3 Recycling Robot"
                                }
                            ]
                        }
                    ],
                    "index": 0,
                    "level": 1
                },
                {
                    "bbox": [
                        78,
                        165,
                        477,
                        322
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                78,
                                165,
                                477,
                                322
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        78,
                                        165,
                                        477,
                                        322
                                    ],
                                    "type": "text",
                                    "content": "A mobile robot has the job of collecting empty soda cans in an office environment. It has sensors for detecting cans, and an arm and gripper that can pick them up and place them in an onboard bin; it runs on a rechargeable battery. The robot's control system has components for interpreting sensory information, for navigating, and for controlling the arm and gripper. High- level decisions about how to search for cans are made by a reinforcement learning agent based on the current charge level of the battery. To make a simple example, we assume that only two charge levels can be distinguished, comprising a small state set "
                                },
                                {
                                    "bbox": [
                                        78,
                                        165,
                                        477,
                                        322
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\mathcal{S} = \\{\\mathrm{high},\\mathrm{low}\\}"
                                },
                                {
                                    "bbox": [
                                        78,
                                        165,
                                        477,
                                        322
                                    ],
                                    "type": "text",
                                    "content": ". In each state, the agent can decide whether to (1) actively search for a can for a certain period of time, (2) remain stationary and wait for someone to bring it a can, or (3) head back to its home base to recharge its battery. When the energy level is high, recharging would always be foolish, so we do not include it in the action set for this state. The action sets are then "
                                },
                                {
                                    "bbox": [
                                        78,
                                        165,
                                        477,
                                        322
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\mathcal{A}(\\mathrm{high}) = \\{\\mathrm{search},\\mathrm{wait}\\}"
                                },
                                {
                                    "bbox": [
                                        78,
                                        165,
                                        477,
                                        322
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        78,
                                        165,
                                        477,
                                        322
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\mathcal{A}(\\mathrm{low}) = \\{\\mathrm{search},\\mathrm{wait},\\mathrm{recharge}\\}"
                                },
                                {
                                    "bbox": [
                                        78,
                                        165,
                                        477,
                                        322
                                    ],
                                    "type": "text",
                                    "content": "."
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        78,
                        325,
                        476,
                        556
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                78,
                                325,
                                476,
                                556
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        78,
                                        325,
                                        476,
                                        556
                                    ],
                                    "type": "text",
                                    "content": "The rewards are zero most of the time, but become positive when the robot secures an empty can, or large and negative if the battery runs all the way down. The best way to find cans is to actively search for them, but this runs down the robot's battery, whereas waiting does not. Whenever the robot is searching, the possibility exists that its battery will become depleted. In this case the robot must shut down and wait to be rescued (producing a low reward). If the energy level is high, then a period of active search can always be completed without risk of depleting the battery. A period of searching that begins with a high energy level leaves the energy level high with probability "
                                },
                                {
                                    "bbox": [
                                        78,
                                        325,
                                        476,
                                        556
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\alpha"
                                },
                                {
                                    "bbox": [
                                        78,
                                        325,
                                        476,
                                        556
                                    ],
                                    "type": "text",
                                    "content": " and reduces it to low with probability "
                                },
                                {
                                    "bbox": [
                                        78,
                                        325,
                                        476,
                                        556
                                    ],
                                    "type": "inline_equation",
                                    "content": "1 - \\alpha"
                                },
                                {
                                    "bbox": [
                                        78,
                                        325,
                                        476,
                                        556
                                    ],
                                    "type": "text",
                                    "content": ". On the other hand, a period of searching undertaken when the energy level is low leaves it low with probability "
                                },
                                {
                                    "bbox": [
                                        78,
                                        325,
                                        476,
                                        556
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\beta"
                                },
                                {
                                    "bbox": [
                                        78,
                                        325,
                                        476,
                                        556
                                    ],
                                    "type": "text",
                                    "content": " and depletes the battery with probability "
                                },
                                {
                                    "bbox": [
                                        78,
                                        325,
                                        476,
                                        556
                                    ],
                                    "type": "inline_equation",
                                    "content": "1 - \\beta"
                                },
                                {
                                    "bbox": [
                                        78,
                                        325,
                                        476,
                                        556
                                    ],
                                    "type": "text",
                                    "content": ". In the latter case, the robot must be rescued, and the battery is then recharged back to high. Each can collected by the robot counts as a unit reward, whereas a reward of "
                                },
                                {
                                    "bbox": [
                                        78,
                                        325,
                                        476,
                                        556
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 3"
                                },
                                {
                                    "bbox": [
                                        78,
                                        325,
                                        476,
                                        556
                                    ],
                                    "type": "text",
                                    "content": " results whenever the robot has to be rescued. Let "
                                },
                                {
                                    "bbox": [
                                        78,
                                        325,
                                        476,
                                        556
                                    ],
                                    "type": "inline_equation",
                                    "content": "r_{\\mathrm{search}}"
                                },
                                {
                                    "bbox": [
                                        78,
                                        325,
                                        476,
                                        556
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        78,
                                        325,
                                        476,
                                        556
                                    ],
                                    "type": "inline_equation",
                                    "content": "r_{\\mathrm{wait}}"
                                },
                                {
                                    "bbox": [
                                        78,
                                        325,
                                        476,
                                        556
                                    ],
                                    "type": "text",
                                    "content": ", with "
                                },
                                {
                                    "bbox": [
                                        78,
                                        325,
                                        476,
                                        556
                                    ],
                                    "type": "inline_equation",
                                    "content": "r_{\\mathrm{search}} > r_{\\mathrm{wait}}"
                                },
                                {
                                    "bbox": [
                                        78,
                                        325,
                                        476,
                                        556
                                    ],
                                    "type": "text",
                                    "content": ", denote the expected number of cans the robot will collect (and hence the expected reward) while searching and while waiting respectively. Finally, suppose that no cans can be collected during a run home for recharging, and that no cans can be collected on a step in which the battery is depleted. This system is then a finite MDP, and we can write down the transition probabilities and the expected rewards, with dynamics as indicated in the table on the left:"
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "type": "image",
                    "bbox": [
                        77,
                        560,
                        477,
                        677
                    ],
                    "blocks": [
                        {
                            "bbox": [
                                77,
                                560,
                                477,
                                677
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        77,
                                        560,
                                        477,
                                        677
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                77,
                                                560,
                                                477,
                                                677
                                            ],
                                            "type": "image",
                                            "image_path": "15984e238df2fe3f03b41e743e15e5b93d44720aedda77c85707ac57bc26bb84.jpg"
                                        }
                                    ]
                                }
                            ],
                            "index": 3,
                            "type": "image_body"
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        77,
                        683,
                        477,
                        720
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                77,
                                683,
                                477,
                                720
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        77,
                                        683,
                                        477,
                                        720
                                    ],
                                    "type": "text",
                                    "content": "Note that there is a row in the table for each possible combination of current state, "
                                },
                                {
                                    "bbox": [
                                        77,
                                        683,
                                        477,
                                        720
                                    ],
                                    "type": "inline_equation",
                                    "content": "s"
                                },
                                {
                                    "bbox": [
                                        77,
                                        683,
                                        477,
                                        720
                                    ],
                                    "type": "text",
                                    "content": ", action, "
                                },
                                {
                                    "bbox": [
                                        77,
                                        683,
                                        477,
                                        720
                                    ],
                                    "type": "inline_equation",
                                    "content": "a \\in \\mathcal{A}(s)"
                                },
                                {
                                    "bbox": [
                                        77,
                                        683,
                                        477,
                                        720
                                    ],
                                    "type": "text",
                                    "content": ", and next state, "
                                },
                                {
                                    "bbox": [
                                        77,
                                        683,
                                        477,
                                        720
                                    ],
                                    "type": "inline_equation",
                                    "content": "s'"
                                },
                                {
                                    "bbox": [
                                        77,
                                        683,
                                        477,
                                        720
                                    ],
                                    "type": "text",
                                    "content": ". Some transitions have zero probability of occurring, so no expected reward is specified for them. Shown on the right is another useful way of"
                                }
                            ]
                        }
                    ],
                    "index": 4
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 5
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        117,
                        145,
                        517,
                        268
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                117,
                                145,
                                517,
                                268
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "text",
                                    "content": "summarizing the dynamics of a finite MDP, as a transition graph. There are two kinds of nodes: state nodes and action nodes. There is a state node for each possible state (a large open circle labeled by the name of the state), and an action node for each state- action pair (a small solid circle labeled by the name of the action and connected by a line to the state node). Starting in state "
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "inline_equation",
                                    "content": "s"
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "text",
                                    "content": " and taking action "
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "inline_equation",
                                    "content": "a"
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "text",
                                    "content": " moves you along the line from state node "
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "inline_equation",
                                    "content": "s"
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "text",
                                    "content": " to action node "
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "inline_equation",
                                    "content": "(s,a)"
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "text",
                                    "content": ". Then the environment responds with a transition to the next state's node via one of the arrows leaving action node "
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "inline_equation",
                                    "content": "(s,a)"
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "text",
                                    "content": ". Each arrow corresponds to a triple "
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "inline_equation",
                                    "content": "(s,s',a)"
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "text",
                                    "content": ", where "
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "inline_equation",
                                    "content": "s'"
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "text",
                                    "content": " is the next state, and we label the arrow with the transition probability, "
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "inline_equation",
                                    "content": "p(s'|s,a)"
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "text",
                                    "content": ", and the expected reward for that transition, "
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "inline_equation",
                                    "content": "r(s,a,s')"
                                },
                                {
                                    "bbox": [
                                        117,
                                        145,
                                        517,
                                        268
                                    ],
                                    "type": "text",
                                    "content": ". Note that the transition probabilities labeling the arrows leaving an action node always sum to 1."
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        104,
                        285,
                        530,
                        325
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                285,
                                530,
                                325
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        285,
                                        530,
                                        325
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.4 Give a table analogous to that in Example 3.3, but for "
                                },
                                {
                                    "bbox": [
                                        104,
                                        285,
                                        530,
                                        325
                                    ],
                                    "type": "inline_equation",
                                    "content": "p(s',r|s,a)"
                                },
                                {
                                    "bbox": [
                                        104,
                                        285,
                                        530,
                                        325
                                    ],
                                    "type": "text",
                                    "content": ". It should have columns for "
                                },
                                {
                                    "bbox": [
                                        104,
                                        285,
                                        530,
                                        325
                                    ],
                                    "type": "inline_equation",
                                    "content": "s"
                                },
                                {
                                    "bbox": [
                                        104,
                                        285,
                                        530,
                                        325
                                    ],
                                    "type": "text",
                                    "content": ", "
                                },
                                {
                                    "bbox": [
                                        104,
                                        285,
                                        530,
                                        325
                                    ],
                                    "type": "inline_equation",
                                    "content": "a"
                                },
                                {
                                    "bbox": [
                                        104,
                                        285,
                                        530,
                                        325
                                    ],
                                    "type": "text",
                                    "content": ", "
                                },
                                {
                                    "bbox": [
                                        104,
                                        285,
                                        530,
                                        325
                                    ],
                                    "type": "inline_equation",
                                    "content": "s'"
                                },
                                {
                                    "bbox": [
                                        104,
                                        285,
                                        530,
                                        325
                                    ],
                                    "type": "text",
                                    "content": ", "
                                },
                                {
                                    "bbox": [
                                        104,
                                        285,
                                        530,
                                        325
                                    ],
                                    "type": "inline_equation",
                                    "content": "r"
                                },
                                {
                                    "bbox": [
                                        104,
                                        285,
                                        530,
                                        325
                                    ],
                                    "type": "text",
                                    "content": ", and "
                                },
                                {
                                    "bbox": [
                                        104,
                                        285,
                                        530,
                                        325
                                    ],
                                    "type": "inline_equation",
                                    "content": "p(s',r|s,a)"
                                },
                                {
                                    "bbox": [
                                        104,
                                        285,
                                        530,
                                        325
                                    ],
                                    "type": "text",
                                    "content": ", and a row for every 4- tuple for which "
                                },
                                {
                                    "bbox": [
                                        104,
                                        285,
                                        530,
                                        325
                                    ],
                                    "type": "inline_equation",
                                    "content": "p(s',r|s,a) > 0"
                                },
                                {
                                    "bbox": [
                                        104,
                                        285,
                                        530,
                                        325
                                    ],
                                    "type": "text",
                                    "content": "."
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        104,
                        346,
                        298,
                        363
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                346,
                                298,
                                363
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        346,
                                        298,
                                        363
                                    ],
                                    "type": "text",
                                    "content": "3.2 Goals and Rewards"
                                }
                            ]
                        }
                    ],
                    "index": 2,
                    "level": 1
                },
                {
                    "bbox": [
                        104,
                        374,
                        530,
                        454
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                374,
                                530,
                                454
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        374,
                                        530,
                                        454
                                    ],
                                    "type": "text",
                                    "content": "In reinforcement learning, the purpose or goal of the agent is formalized in terms of a special signal, called the reward, passing from the environment to the agent. At each time step, the reward is a simple number, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        374,
                                        530,
                                        454
                                    ],
                                    "type": "inline_equation",
                                    "content": "R_t \\in \\mathbb{R}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        374,
                                        530,
                                        454
                                    ],
                                    "type": "text",
                                    "content": ". Informally, the agent's goal is to maximize the total amount of reward it receives. This means maximizing not immediate reward, but cumulative reward in the long run. We can clearly state this informal idea as the reward hypothesis:"
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        131,
                        463,
                        503,
                        503
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                131,
                                463,
                                503,
                                503
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        131,
                                        463,
                                        503,
                                        503
                                    ],
                                    "type": "text",
                                    "content": "That all of what we mean by goals and purposes can be well thought of as the maximization of the expected value of the cumulative sum of a received scalar signal (called reward)."
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        104,
                        512,
                        530,
                        539
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                512,
                                530,
                                539
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        512,
                                        530,
                                        539
                                    ],
                                    "type": "text",
                                    "content": "The use of a reward signal to formalize the idea of a goal is one of the most distinctive features of reinforcement learning."
                                }
                            ]
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        104,
                        540,
                        530,
                        698
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                540,
                                530,
                                698
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        540,
                                        530,
                                        698
                                    ],
                                    "type": "text",
                                    "content": "Although formulating goals in terms of reward signals might at first appear limiting, in practice it has proved to be flexible and widely applicable. The best way to see this is to consider examples of how it has been, or could be, used. For example, to make a robot learn to walk, researchers have provided reward on each time step proportional to the robot's forward motion. In making a robot learn how to escape from a maze, the reward is often "
                                },
                                {
                                    "bbox": [
                                        104,
                                        540,
                                        530,
                                        698
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 1"
                                },
                                {
                                    "bbox": [
                                        104,
                                        540,
                                        530,
                                        698
                                    ],
                                    "type": "text",
                                    "content": " for every time step that passes prior to escape; this encourages the agent to escape as quickly as possible. To make a robot learn to find and collect empty soda cans for recycling, one might give it a reward of zero most of the time, and then a reward of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        540,
                                        530,
                                        698
                                    ],
                                    "type": "inline_equation",
                                    "content": "+1"
                                },
                                {
                                    "bbox": [
                                        104,
                                        540,
                                        530,
                                        698
                                    ],
                                    "type": "text",
                                    "content": " for each can collected. One might also want to give the robot negative rewards when it bumps into things or when somebody yells at it. For an agent to learn to play checkers or chess, the natural rewards are "
                                },
                                {
                                    "bbox": [
                                        104,
                                        540,
                                        530,
                                        698
                                    ],
                                    "type": "inline_equation",
                                    "content": "+1"
                                },
                                {
                                    "bbox": [
                                        104,
                                        540,
                                        530,
                                        698
                                    ],
                                    "type": "text",
                                    "content": " for winning, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        540,
                                        530,
                                        698
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 1"
                                },
                                {
                                    "bbox": [
                                        104,
                                        540,
                                        530,
                                        698
                                    ],
                                    "type": "text",
                                    "content": " for losing, and "
                                },
                                {
                                    "bbox": [
                                        104,
                                        540,
                                        530,
                                        698
                                    ],
                                    "type": "inline_equation",
                                    "content": "0"
                                },
                                {
                                    "bbox": [
                                        104,
                                        540,
                                        530,
                                        698
                                    ],
                                    "type": "text",
                                    "content": " for drawing and for all nonterminal positions."
                                }
                            ]
                        }
                    ],
                    "index": 6
                },
                {
                    "bbox": [
                        104,
                        700,
                        530,
                        740
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                700,
                                530,
                                740
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        700,
                                        530,
                                        740
                                    ],
                                    "type": "text",
                                    "content": "You can see what is happening in all of these examples. The agent always learns to maximize its reward. If we want it to do something for us, we must provide rewards to it in such a way that in maximizing them the agent will also achieve our goals. It"
                                }
                            ]
                        }
                    ],
                    "index": 7
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 6
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        64,
                        140,
                        490,
                        260
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                140,
                                490,
                                260
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        140,
                                        490,
                                        260
                                    ],
                                    "type": "text",
                                    "content": "is thus critical that the rewards we set up truly indicate what we want accomplished. In particular, the reward signal is not the place to impart to the agent prior knowledge about how to achieve what we want it to do.<sup>5</sup> For example, a chess- playing agent should be rewarded only for actually winning, not for achieving subgoals such as taking its opponent's pieces or aiming control of the center of the board. If achieving these sorts of subgoals were rewarded, then the agent might find a way to achieve them without achieving the real goal. For example, it might find a way to take the opponent's pieces even at the cost of losing the game. The reward signal is your way of communicating to the agent what you want achieved, not how you want it achieved.<sup>6</sup>"
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        64,
                        282,
                        278,
                        299
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                282,
                                278,
                                299
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        282,
                                        278,
                                        299
                                    ],
                                    "type": "text",
                                    "content": "3.3 Returns and Episodes"
                                }
                            ]
                        }
                    ],
                    "index": 1,
                    "level": 1
                },
                {
                    "bbox": [
                        64,
                        310,
                        490,
                        404
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                310,
                                490,
                                404
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        310,
                                        490,
                                        404
                                    ],
                                    "type": "text",
                                    "content": "So far we have discussed informally the objective of learning. We have said that the agent's goal is to maximize the cumulative reward it receives in the long run. How might this be defined formally? If the sequence of rewards received after time step "
                                },
                                {
                                    "bbox": [
                                        64,
                                        310,
                                        490,
                                        404
                                    ],
                                    "type": "inline_equation",
                                    "content": "t"
                                },
                                {
                                    "bbox": [
                                        64,
                                        310,
                                        490,
                                        404
                                    ],
                                    "type": "text",
                                    "content": " is denoted "
                                },
                                {
                                    "bbox": [
                                        64,
                                        310,
                                        490,
                                        404
                                    ],
                                    "type": "inline_equation",
                                    "content": "R_{t + 1}, R_{t + 2}, R_{t + 3}, \\ldots"
                                },
                                {
                                    "bbox": [
                                        64,
                                        310,
                                        490,
                                        404
                                    ],
                                    "type": "text",
                                    "content": ", then what precise aspect of this sequence do we wish to maximize? In general, we seek to maximize the expected return, where the return, denoted "
                                },
                                {
                                    "bbox": [
                                        64,
                                        310,
                                        490,
                                        404
                                    ],
                                    "type": "inline_equation",
                                    "content": "G_{t}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        310,
                                        490,
                                        404
                                    ],
                                    "type": "text",
                                    "content": ", is defined as some specific function of the reward sequence. In the simplest case the return is the sum of the rewards:"
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        92,
                        415,
                        488,
                        429
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                92,
                                415,
                                488,
                                429
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        92,
                                        415,
                                        488,
                                        429
                                    ],
                                    "type": "interline_equation",
                                    "content": "G_{t} = R_{t + 1} + R_{t + 2} + R_{t + 3} + \\dots + R_{T}, \\tag{3.7}",
                                    "image_path": "7ffe91674da14e8066c126fdcb262fcba57debde89e2ea898f9301c9a75780f2.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        64,
                        439,
                        490,
                        612
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                439,
                                490,
                                612
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        439,
                                        490,
                                        612
                                    ],
                                    "type": "text",
                                    "content": "where "
                                },
                                {
                                    "bbox": [
                                        64,
                                        439,
                                        490,
                                        612
                                    ],
                                    "type": "inline_equation",
                                    "content": "T"
                                },
                                {
                                    "bbox": [
                                        64,
                                        439,
                                        490,
                                        612
                                    ],
                                    "type": "text",
                                    "content": " is a final time step. This approach makes sense in applications in which there is a natural notion of final time step, that is, when the agent- environment interaction breaks naturally into subsequences, which we call episodes,<sup>7</sup> such as plays of a game, trips through a maze, or any sort of repeated interaction. Each episode ends in a special state called the terminal state, followed by a reset to a standard starting state or to a sample from a standard distribution of starting states. Even if you think of episodes as ending in different ways, such as winning and losing a game, the next episode begins independently of how the previous one ended. Thus the episodes can all be considered to end in the same terminal state, with different rewards for the different outcomes. Tasks with episodes of this kind are called episodic tasks. In episodic tasks we sometimes need to distinguish the set of all nonterminal states, denoted "
                                },
                                {
                                    "bbox": [
                                        64,
                                        439,
                                        490,
                                        612
                                    ],
                                    "type": "inline_equation",
                                    "content": "S"
                                },
                                {
                                    "bbox": [
                                        64,
                                        439,
                                        490,
                                        612
                                    ],
                                    "type": "text",
                                    "content": ", from the set of all states plus the terminal state, denoted "
                                },
                                {
                                    "bbox": [
                                        64,
                                        439,
                                        490,
                                        612
                                    ],
                                    "type": "inline_equation",
                                    "content": "S^{+}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        439,
                                        490,
                                        612
                                    ],
                                    "type": "text",
                                    "content": ". The time of termination, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        439,
                                        490,
                                        612
                                    ],
                                    "type": "inline_equation",
                                    "content": "T"
                                },
                                {
                                    "bbox": [
                                        64,
                                        439,
                                        490,
                                        612
                                    ],
                                    "type": "text",
                                    "content": ", is a random variable that normally varies from episode to episode."
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        64,
                        613,
                        490,
                        692
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                613,
                                490,
                                692
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        613,
                                        490,
                                        692
                                    ],
                                    "type": "text",
                                    "content": "On the other hand, in many cases the agent- environment interaction does not break naturally into identifiable episodes, but goes on continually without limit. For example, this would be the natural way to formulate an on- going process- control task, or an application to a robot with a long life span. We call these continuing tasks. The return formulation (3.7) is problematic for continuing tasks because the final time step would be "
                                },
                                {
                                    "bbox": [
                                        64,
                                        613,
                                        490,
                                        692
                                    ],
                                    "type": "inline_equation",
                                    "content": "T = \\infty"
                                },
                                {
                                    "bbox": [
                                        64,
                                        613,
                                        490,
                                        692
                                    ],
                                    "type": "text",
                                    "content": ", and the return, which is what we are trying to maximize, could easily be infinite."
                                }
                            ]
                        }
                    ],
                    "index": 5
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 7
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        104,
                        141,
                        530,
                        181
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                141,
                                530,
                                181
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        181
                                    ],
                                    "type": "text",
                                    "content": "(For example, suppose the agent receives a reward of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        181
                                    ],
                                    "type": "inline_equation",
                                    "content": "+1"
                                },
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        181
                                    ],
                                    "type": "text",
                                    "content": " at each time step.) Thus, in this book we usually use a definition of return that is slightly more complex conceptually but much simpler mathematically."
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        104,
                        181,
                        530,
                        234
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                181,
                                530,
                                234
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        181,
                                        530,
                                        234
                                    ],
                                    "type": "text",
                                    "content": "The additional concept that we need is that of discounting. According to this approach, the agent tries to select actions so that the sum of the discounted rewards it receives over the future is maximized. In particular, it chooses "
                                },
                                {
                                    "bbox": [
                                        104,
                                        181,
                                        530,
                                        234
                                    ],
                                    "type": "inline_equation",
                                    "content": "A_{t}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        181,
                                        530,
                                        234
                                    ],
                                    "type": "text",
                                    "content": " to maximize the expected discounted return:"
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        132,
                        241,
                        528,
                        277
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                132,
                                241,
                                528,
                                277
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        132,
                                        241,
                                        528,
                                        277
                                    ],
                                    "type": "interline_equation",
                                    "content": "G_{t} \\doteq R_{t + 1} + \\gamma R_{t + 2} + \\gamma^{2}R_{t + 3} + \\dots = \\sum_{k = 0}^{\\infty} \\gamma^{k} R_{t + k + 1}, \\tag{3.8}",
                                    "image_path": "77f28a4fd89ac0d54d6a913dc4e3307307c01edef6c836b66c9f629e0eb0dd17.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        104,
                        286,
                        392,
                        299
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                286,
                                392,
                                299
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        286,
                                        392,
                                        299
                                    ],
                                    "type": "text",
                                    "content": "where "
                                },
                                {
                                    "bbox": [
                                        104,
                                        286,
                                        392,
                                        299
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\gamma"
                                },
                                {
                                    "bbox": [
                                        104,
                                        286,
                                        392,
                                        299
                                    ],
                                    "type": "text",
                                    "content": " is a parameter, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        286,
                                        392,
                                        299
                                    ],
                                    "type": "inline_equation",
                                    "content": "0 \\leq \\gamma \\leq 1"
                                },
                                {
                                    "bbox": [
                                        104,
                                        286,
                                        392,
                                        299
                                    ],
                                    "type": "text",
                                    "content": ", called the discount rate."
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        104,
                        300,
                        530,
                        446
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                300,
                                530,
                                446
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        300,
                                        530,
                                        446
                                    ],
                                    "type": "text",
                                    "content": "The discount rate determines the present value of future rewards: a reward received "
                                },
                                {
                                    "bbox": [
                                        104,
                                        300,
                                        530,
                                        446
                                    ],
                                    "type": "inline_equation",
                                    "content": "k"
                                },
                                {
                                    "bbox": [
                                        104,
                                        300,
                                        530,
                                        446
                                    ],
                                    "type": "text",
                                    "content": " time steps in the future is worth only "
                                },
                                {
                                    "bbox": [
                                        104,
                                        300,
                                        530,
                                        446
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\gamma^{k - 1}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        300,
                                        530,
                                        446
                                    ],
                                    "type": "text",
                                    "content": " times what it would be worth if it were received immediately. If "
                                },
                                {
                                    "bbox": [
                                        104,
                                        300,
                                        530,
                                        446
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\gamma < 1"
                                },
                                {
                                    "bbox": [
                                        104,
                                        300,
                                        530,
                                        446
                                    ],
                                    "type": "text",
                                    "content": ", the infinite sum in (3.8) has a finite value as long as the reward sequence "
                                },
                                {
                                    "bbox": [
                                        104,
                                        300,
                                        530,
                                        446
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\{R_{k}\\}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        300,
                                        530,
                                        446
                                    ],
                                    "type": "text",
                                    "content": " is bounded. If "
                                },
                                {
                                    "bbox": [
                                        104,
                                        300,
                                        530,
                                        446
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\gamma = 0"
                                },
                                {
                                    "bbox": [
                                        104,
                                        300,
                                        530,
                                        446
                                    ],
                                    "type": "text",
                                    "content": ", the agent is \"myopic\" in being concerned only with maximizing immediate rewards: its objective in this case is to learn how to choose "
                                },
                                {
                                    "bbox": [
                                        104,
                                        300,
                                        530,
                                        446
                                    ],
                                    "type": "inline_equation",
                                    "content": "A_{t}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        300,
                                        530,
                                        446
                                    ],
                                    "type": "text",
                                    "content": " so as to maximize only "
                                },
                                {
                                    "bbox": [
                                        104,
                                        300,
                                        530,
                                        446
                                    ],
                                    "type": "inline_equation",
                                    "content": "R_{t + 1}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        300,
                                        530,
                                        446
                                    ],
                                    "type": "text",
                                    "content": ". If each of the agent's actions happened to influence only the immediate reward, not future rewards as well, then a myopic agent could maximize (3.8) by separately maximizing each immediate reward. But in general, acting to maximize immediate reward can reduce access to future rewards so that the return is reduced. As "
                                },
                                {
                                    "bbox": [
                                        104,
                                        300,
                                        530,
                                        446
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\gamma"
                                },
                                {
                                    "bbox": [
                                        104,
                                        300,
                                        530,
                                        446
                                    ],
                                    "type": "text",
                                    "content": " approaches 1, the return objective takes future rewards into account more strongly; the agent becomes more farsighted."
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        104,
                        447,
                        530,
                        474
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                447,
                                530,
                                474
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        530,
                                        474
                                    ],
                                    "type": "text",
                                    "content": "Returns at successive time steps are related to each other in a way that is important for the theory and algorithms of reinforcement learning:"
                                }
                            ]
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        131,
                        482,
                        528,
                        535
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                131,
                                482,
                                528,
                                535
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        131,
                                        482,
                                        528,
                                        535
                                    ],
                                    "type": "interline_equation",
                                    "content": "\\begin{array}{l}{{G_{t}\\doteq R_{t+1}+\\gamma R_{t+2}+\\gamma^{2}R_{t+3}+\\gamma^{3}R_{t+4}+\\cdots}}\\\\ {{\\mathrm{~}=R_{t+1}+\\gamma\\big(R_{t+2}+\\gamma R_{t+3}+\\gamma^{2}R_{t+4}+\\cdots\\big)}}\\\\ {{\\mathrm{~}=R_{t+1}+\\gamma G_{t+1}}}\\end{array} \\tag{3.9}",
                                    "image_path": "c2322348fdebcec6607b18151134758730bc71c33ff4a3bc32676078aabcc900.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 6
                },
                {
                    "bbox": [
                        104,
                        543,
                        530,
                        570
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                543,
                                530,
                                570
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        543,
                                        530,
                                        570
                                    ],
                                    "type": "text",
                                    "content": "Note that this works for all time steps "
                                },
                                {
                                    "bbox": [
                                        104,
                                        543,
                                        530,
                                        570
                                    ],
                                    "type": "inline_equation",
                                    "content": "t < T"
                                },
                                {
                                    "bbox": [
                                        104,
                                        543,
                                        530,
                                        570
                                    ],
                                    "type": "text",
                                    "content": ", even if termination occurs at "
                                },
                                {
                                    "bbox": [
                                        104,
                                        543,
                                        530,
                                        570
                                    ],
                                    "type": "inline_equation",
                                    "content": "t + 1"
                                },
                                {
                                    "bbox": [
                                        104,
                                        543,
                                        530,
                                        570
                                    ],
                                    "type": "text",
                                    "content": ", provided we define "
                                },
                                {
                                    "bbox": [
                                        104,
                                        543,
                                        530,
                                        570
                                    ],
                                    "type": "inline_equation",
                                    "content": "G_{T} = 0"
                                },
                                {
                                    "bbox": [
                                        104,
                                        543,
                                        530,
                                        570
                                    ],
                                    "type": "text",
                                    "content": ". This often makes it easy to compute returns from reward sequences."
                                }
                            ]
                        }
                    ],
                    "index": 7
                },
                {
                    "bbox": [
                        104,
                        571,
                        530,
                        612
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                571,
                                530,
                                612
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        571,
                                        530,
                                        612
                                    ],
                                    "type": "text",
                                    "content": "Note that although the return (3.8) is a sum of an infinite number of terms, it is still finite if the reward is nonzero and constantâ€”if "
                                },
                                {
                                    "bbox": [
                                        104,
                                        571,
                                        530,
                                        612
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\gamma < 1"
                                },
                                {
                                    "bbox": [
                                        104,
                                        571,
                                        530,
                                        612
                                    ],
                                    "type": "text",
                                    "content": ". For example, if the reward is a constant "
                                },
                                {
                                    "bbox": [
                                        104,
                                        571,
                                        530,
                                        612
                                    ],
                                    "type": "inline_equation",
                                    "content": "+1"
                                },
                                {
                                    "bbox": [
                                        104,
                                        571,
                                        530,
                                        612
                                    ],
                                    "type": "text",
                                    "content": ", then the return is"
                                }
                            ]
                        }
                    ],
                    "index": 8
                },
                {
                    "bbox": [
                        131,
                        620,
                        528,
                        656
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                131,
                                620,
                                528,
                                656
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        131,
                                        620,
                                        528,
                                        656
                                    ],
                                    "type": "interline_equation",
                                    "content": "G_{t} = \\sum_{k = 0}^{\\infty} \\gamma^{k} = \\frac{1}{1 - \\gamma}. \\tag{3.10}",
                                    "image_path": "75d6fd7561c739e2187987898b024ea85ac78837b992121bde55c1ddaed73888.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 9
                },
                {
                    "bbox": [
                        104,
                        676,
                        530,
                        717
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                676,
                                530,
                                717
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        676,
                                        530,
                                        717
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.5 The equations in Section 3.1 are for the continuing case and need to be modified (very slightly) to apply to episodic tasks. Show that you know the modifications needed by giving the modified version of (3.3)."
                                }
                            ]
                        }
                    ],
                    "index": 10
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 8
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        64,
                        141,
                        226,
                        154
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                141,
                                226,
                                154
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        141,
                                        226,
                                        154
                                    ],
                                    "type": "text",
                                    "content": "Example 3.4: Pole-Balancing"
                                }
                            ]
                        }
                    ],
                    "index": 0,
                    "level": 1
                },
                {
                    "bbox": [
                        64,
                        154,
                        248,
                        272
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                154,
                                248,
                                272
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        154,
                                        248,
                                        272
                                    ],
                                    "type": "text",
                                    "content": "The objective in this task is to apply forces to a cart moving along a track so as to keep a pole hinged to the cart from falling over: A failure is said to occur if the pole falls past a given angle from vertical or if the cart runs off the track. The pole is reset to vertical after each failure. This task could be treated as episodic, where the natural"
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "type": "image",
                    "bbox": [
                        258,
                        143,
                        487,
                        262
                    ],
                    "blocks": [
                        {
                            "bbox": [
                                258,
                                143,
                                487,
                                262
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        258,
                                        143,
                                        487,
                                        262
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                258,
                                                143,
                                                487,
                                                262
                                            ],
                                            "type": "image",
                                            "image_path": "88d541748073975b3be2d6d85dcd0d4a01c372dc4dbd754e0a17304df4720121.jpg"
                                        }
                                    ]
                                }
                            ],
                            "index": 2,
                            "type": "image_body"
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        64,
                        273,
                        489,
                        379
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                273,
                                489,
                                379
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        273,
                                        489,
                                        379
                                    ],
                                    "type": "text",
                                    "content": "episodes are the repeated attempts to balance the pole. The reward in this case could be "
                                },
                                {
                                    "bbox": [
                                        64,
                                        273,
                                        489,
                                        379
                                    ],
                                    "type": "inline_equation",
                                    "content": "+1"
                                },
                                {
                                    "bbox": [
                                        64,
                                        273,
                                        489,
                                        379
                                    ],
                                    "type": "text",
                                    "content": " for every time step on which failure did not occur, so that the return at each time would be the number of steps until failure. In this case, successful balancing forever would mean a return of infinity. Alternatively, we could treat pole- balancing as a continuing task, using discounting. In this case the reward would be "
                                },
                                {
                                    "bbox": [
                                        64,
                                        273,
                                        489,
                                        379
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 1"
                                },
                                {
                                    "bbox": [
                                        64,
                                        273,
                                        489,
                                        379
                                    ],
                                    "type": "text",
                                    "content": " on each failure and zero at all other times. The return at each time would then be related to "
                                },
                                {
                                    "bbox": [
                                        64,
                                        273,
                                        489,
                                        379
                                    ],
                                    "type": "inline_equation",
                                    "content": "- \\gamma^{K - 1}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        273,
                                        489,
                                        379
                                    ],
                                    "type": "text",
                                    "content": ", where "
                                },
                                {
                                    "bbox": [
                                        64,
                                        273,
                                        489,
                                        379
                                    ],
                                    "type": "inline_equation",
                                    "content": "K"
                                },
                                {
                                    "bbox": [
                                        64,
                                        273,
                                        489,
                                        379
                                    ],
                                    "type": "text",
                                    "content": " is the number of time steps before failure (as well as to the times of later failures). In either case, the return is maximized by keeping the pole balanced for as long as possible."
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        64,
                        397,
                        489,
                        449
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                397,
                                489,
                                449
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        397,
                                        489,
                                        449
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.6 Suppose you treated pole- balancing as an episodic task but also used discounting, with all rewards zero except for "
                                },
                                {
                                    "bbox": [
                                        64,
                                        397,
                                        489,
                                        449
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 1"
                                },
                                {
                                    "bbox": [
                                        64,
                                        397,
                                        489,
                                        449
                                    ],
                                    "type": "text",
                                    "content": " upon failure. What then would the return be at each time? How does this return differ from that in the discounted, continuing formulation of this task?"
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        64,
                        454,
                        489,
                        547
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                454,
                                489,
                                547
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        454,
                                        489,
                                        547
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.7 Imagine that you are designing a robot to run a maze. You decide to give it a reward of "
                                },
                                {
                                    "bbox": [
                                        64,
                                        454,
                                        489,
                                        547
                                    ],
                                    "type": "inline_equation",
                                    "content": "+1"
                                },
                                {
                                    "bbox": [
                                        64,
                                        454,
                                        489,
                                        547
                                    ],
                                    "type": "text",
                                    "content": " for escaping from the maze and a reward of zero at all other times. The task seems to break down naturally into episodesâ€”the successive runs through the mazeâ€”so you decide to treat it as an episodic task, where the goal is to maximize expected total reward (3.7). After running the learning agent for a while, you find that it is showing no improvement in escaping from the maze. What is going wrong? Have you effectively communicated to the agent what you want it to achieve?"
                                }
                            ]
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        64,
                        552,
                        490,
                        591
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                552,
                                490,
                                591
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.8 Suppose "
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\gamma = 0.5"
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "text",
                                    "content": " and the following sequence of rewards is received "
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "inline_equation",
                                    "content": "R_{1} = - 1"
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "text",
                                    "content": ", "
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "inline_equation",
                                    "content": "R_{2} = 2"
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "text",
                                    "content": ", "
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "inline_equation",
                                    "content": "R_{3} = 6"
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "text",
                                    "content": ", "
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "inline_equation",
                                    "content": "R_{4} = 3"
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "text",
                                    "content": ", and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "inline_equation",
                                    "content": "R_{5} = 2"
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "text",
                                    "content": ", with "
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "inline_equation",
                                    "content": "T = 5"
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "text",
                                    "content": ". What are "
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "inline_equation",
                                    "content": "G_{0}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "text",
                                    "content": ", "
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "inline_equation",
                                    "content": "G_{1}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "text",
                                    "content": ", ..., "
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "inline_equation",
                                    "content": "G_{5}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        552,
                                        490,
                                        591
                                    ],
                                    "type": "text",
                                    "content": "? Hint: Work backwards."
                                }
                            ]
                        }
                    ],
                    "index": 6
                },
                {
                    "bbox": [
                        64,
                        596,
                        489,
                        623
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                596,
                                489,
                                623
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        596,
                                        489,
                                        623
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.9 Suppose "
                                },
                                {
                                    "bbox": [
                                        64,
                                        596,
                                        489,
                                        623
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\gamma = 0.9"
                                },
                                {
                                    "bbox": [
                                        64,
                                        596,
                                        489,
                                        623
                                    ],
                                    "type": "text",
                                    "content": " and the reward sequence is "
                                },
                                {
                                    "bbox": [
                                        64,
                                        596,
                                        489,
                                        623
                                    ],
                                    "type": "inline_equation",
                                    "content": "R_{1} = 2"
                                },
                                {
                                    "bbox": [
                                        64,
                                        596,
                                        489,
                                        623
                                    ],
                                    "type": "text",
                                    "content": " followed by an infinite sequence of 7s. What are "
                                },
                                {
                                    "bbox": [
                                        64,
                                        596,
                                        489,
                                        623
                                    ],
                                    "type": "inline_equation",
                                    "content": "G_{1}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        596,
                                        489,
                                        623
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        596,
                                        489,
                                        623
                                    ],
                                    "type": "inline_equation",
                                    "content": "G_{0}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        596,
                                        489,
                                        623
                                    ],
                                    "type": "text",
                                    "content": "?"
                                }
                            ]
                        }
                    ],
                    "index": 7
                },
                {
                    "bbox": [
                        64,
                        627,
                        489,
                        640
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                627,
                                489,
                                640
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        627,
                                        489,
                                        640
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.10 Prove the second equality in (3.10)."
                                }
                            ]
                        }
                    ],
                    "index": 8
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 9
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        104,
                        136,
                        542,
                        154
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                136,
                                542,
                                154
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        136,
                                        542,
                                        154
                                    ],
                                    "type": "text",
                                    "content": "3.4 Unified Notation for Episodic and Continuing Tasks"
                                }
                            ]
                        }
                    ],
                    "index": 0,
                    "level": 1
                },
                {
                    "bbox": [
                        104,
                        170,
                        530,
                        262
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                170,
                                530,
                                262
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        170,
                                        530,
                                        262
                                    ],
                                    "type": "text",
                                    "content": "In the preceding section we described two kinds of reinforcement learning tasks, one in which the agent- environment interaction naturally breaks down into a sequence of separate episodes (episodic tasks), and one in which it does not (continuing tasks). The former case is mathematically easier because each action affects only the finite number of rewards subsequently received during the episode. In this book we consider sometimes one kind of problem and sometimes the other, but often both. It is therefore useful to establish one notation that enables us to talk precisely about both cases simultaneously."
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        104,
                        264,
                        530,
                        396
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                264,
                                530,
                                396
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "text",
                                    "content": "To be precise about episodic tasks requires some additional notation. Rather than one long sequence of time steps, we need to consider a series of episodes, each of which consists of a finite sequence of time steps. We number the time steps of each episode starting anew from zero. Therefore, we have to refer not just to "
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "inline_equation",
                                    "content": "S_{t,i}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "text",
                                    "content": " the state representation at time "
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "inline_equation",
                                    "content": "t"
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "text",
                                    "content": " , but to "
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "inline_equation",
                                    "content": "S_{t,i}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "text",
                                    "content": " , the state representation at time "
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "inline_equation",
                                    "content": "t"
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "text",
                                    "content": " of episode "
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "inline_equation",
                                    "content": "i"
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "text",
                                    "content": " (and similarly for "
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "inline_equation",
                                    "content": "A_{t,i}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "inline_equation",
                                    "content": "R_{t,i}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi_{t,i}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "inline_equation",
                                    "content": "T_{i}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "text",
                                    "content": " , etc.). However, it turns out that when we discuss episodic tasks we almost never have to distinguish between different episodes. We are almost always considering a particular episode, or stating something that is true for all episodes. Accordingly, in practice we almost always abuse notation slightly by dropping the explicit reference to episode number. That is, we write "
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "inline_equation",
                                    "content": "S_{t}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "text",
                                    "content": " to refer to "
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "inline_equation",
                                    "content": "S_{t,i}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        264,
                                        530,
                                        396
                                    ],
                                    "type": "text",
                                    "content": " , and so on."
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        104,
                        398,
                        530,
                        478
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                398,
                                530,
                                478
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        398,
                                        530,
                                        478
                                    ],
                                    "type": "text",
                                    "content": "We need one other convention to obtain a single notation that covers both episodic and continuing tasks. We have defined the return as a sum over a finite number of terms in one case (3.7) and as a sum over an infinite number of terms in the other (3.8). These two can be unified by considering episode termination to be the entering of a special absorbing state that transitions only to itself and that generates only rewards of zero. For example, consider the state transition diagram:"
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "type": "image",
                    "bbox": [
                        176,
                        490,
                        452,
                        538
                    ],
                    "blocks": [
                        {
                            "bbox": [
                                176,
                                490,
                                452,
                                538
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        176,
                                        490,
                                        452,
                                        538
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                176,
                                                490,
                                                452,
                                                538
                                            ],
                                            "type": "image",
                                            "image_path": "ffd2be53b0164566a8f25f6e160900d20f8211b7a97947d87472ca9777b9a0ee.jpg"
                                        }
                                    ]
                                }
                            ],
                            "index": 4,
                            "type": "image_body"
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        104,
                        544,
                        530,
                        639
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                544,
                                530,
                                639
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        544,
                                        530,
                                        639
                                    ],
                                    "type": "text",
                                    "content": "Here the solid square represents the special absorbing state corresponding to the end of an episode. Starting from "
                                },
                                {
                                    "bbox": [
                                        104,
                                        544,
                                        530,
                                        639
                                    ],
                                    "type": "inline_equation",
                                    "content": "S_{0}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        544,
                                        530,
                                        639
                                    ],
                                    "type": "text",
                                    "content": " , we get the reward sequence "
                                },
                                {
                                    "bbox": [
                                        104,
                                        544,
                                        530,
                                        639
                                    ],
                                    "type": "inline_equation",
                                    "content": "+1, + 1, + 1,0,0,0,\\ldots"
                                },
                                {
                                    "bbox": [
                                        104,
                                        544,
                                        530,
                                        639
                                    ],
                                    "type": "text",
                                    "content": " Summing these, we get the same return whether we sum over the first "
                                },
                                {
                                    "bbox": [
                                        104,
                                        544,
                                        530,
                                        639
                                    ],
                                    "type": "inline_equation",
                                    "content": "T"
                                },
                                {
                                    "bbox": [
                                        104,
                                        544,
                                        530,
                                        639
                                    ],
                                    "type": "text",
                                    "content": " rewards (here "
                                },
                                {
                                    "bbox": [
                                        104,
                                        544,
                                        530,
                                        639
                                    ],
                                    "type": "inline_equation",
                                    "content": "T = 3"
                                },
                                {
                                    "bbox": [
                                        104,
                                        544,
                                        530,
                                        639
                                    ],
                                    "type": "text",
                                    "content": " ) or over the full infinite sequence. This remains true even if we introduce discounting. Thus, we can define the return, in general, according to (3.8), using the convention of omitting episode numbers when they are not needed, and including the possibility that "
                                },
                                {
                                    "bbox": [
                                        104,
                                        544,
                                        530,
                                        639
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\gamma = 1"
                                },
                                {
                                    "bbox": [
                                        104,
                                        544,
                                        530,
                                        639
                                    ],
                                    "type": "text",
                                    "content": " if the sum remains defined (e.g., because all episodes terminate). Alternatively, we can write"
                                }
                            ]
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        131,
                        657,
                        528,
                        695
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                131,
                                657,
                                528,
                                695
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        131,
                                        657,
                                        528,
                                        695
                                    ],
                                    "type": "interline_equation",
                                    "content": "G_{t}\\doteq \\sum_{k = t + 1}^{T}\\gamma^{k - t - 1}R_{k}, \\tag{3.11}",
                                    "image_path": "45ec0d0ef06b00f9ad4b930f6ca53dc2c820565fe5157610b4164d7f29403d8b.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 6
                },
                {
                    "bbox": [
                        102,
                        713,
                        529,
                        740
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                102,
                                713,
                                529,
                                740
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        102,
                                        713,
                                        529,
                                        740
                                    ],
                                    "type": "text",
                                    "content": "including the possibility that "
                                },
                                {
                                    "bbox": [
                                        102,
                                        713,
                                        529,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "T = \\infty"
                                },
                                {
                                    "bbox": [
                                        102,
                                        713,
                                        529,
                                        740
                                    ],
                                    "type": "text",
                                    "content": " or "
                                },
                                {
                                    "bbox": [
                                        102,
                                        713,
                                        529,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\gamma = 1"
                                },
                                {
                                    "bbox": [
                                        102,
                                        713,
                                        529,
                                        740
                                    ],
                                    "type": "text",
                                    "content": " (but not both). We use these conventions throughout the rest of the book to simplify notation and to express the close parallels"
                                }
                            ]
                        }
                    ],
                    "index": 7
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 10
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        64,
                        140,
                        489,
                        168
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                140,
                                489,
                                168
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        140,
                                        489,
                                        168
                                    ],
                                    "type": "text",
                                    "content": "between episodic and continuing tasks. (Later, in Chapter 10, we will introduce a formulation that is both continuing and undiscounted.)"
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        64,
                        187,
                        331,
                        205
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                187,
                                331,
                                205
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        187,
                                        331,
                                        205
                                    ],
                                    "type": "text",
                                    "content": "3.5 Policies and Value Functions"
                                }
                            ]
                        }
                    ],
                    "index": 1,
                    "level": 1
                },
                {
                    "bbox": [
                        64,
                        216,
                        489,
                        309
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                216,
                                489,
                                309
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        216,
                                        489,
                                        309
                                    ],
                                    "type": "text",
                                    "content": "Almost all reinforcement learning algorithms involve estimating value functionsâ€”functions of states (or of state- action pairs) that estimate how good it is for the agent to be in a given state (or how good it is to perform a given action in a given state). The notion of \"how good\" here is defined in terms of future rewards that can be expected, or, to be precise, in terms of expected return. Of course the rewards the agent can expect to receive in the future depend on what actions it will take. Accordingly, value functions are defined with respect to particular ways of acting, called policies."
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        64,
                        311,
                        489,
                        390
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                311,
                                489,
                                390
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "text",
                                    "content": "Formally, a policy is a mapping from states to probabilities of selecting each possible action. If the agent is following policy "
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi"
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "text",
                                    "content": " at time "
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "inline_equation",
                                    "content": "t"
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "text",
                                    "content": ", then "
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi (a|s)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "text",
                                    "content": " is the probability that "
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "inline_equation",
                                    "content": "A_{t} = a"
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "text",
                                    "content": " if "
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "inline_equation",
                                    "content": "S_{t} = s"
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "text",
                                    "content": ". Like "
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "inline_equation",
                                    "content": "p"
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "text",
                                    "content": ", "
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi"
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "text",
                                    "content": " is an ordinary function; the \"i\" in the middle of "
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi (a|s)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "text",
                                    "content": " merely reminds us that it defines a probability distribution over "
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "inline_equation",
                                    "content": "a \\in \\mathcal{A}(s)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "text",
                                    "content": " for each "
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "inline_equation",
                                    "content": "s \\in \\mathcal{S}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        311,
                                        489,
                                        390
                                    ],
                                    "type": "text",
                                    "content": ". Reinforcement learning methods specify how the agent's policy is changed as a result of its experience."
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        64,
                        394,
                        489,
                        434
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                394,
                                489,
                                434
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        394,
                                        489,
                                        434
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.11 If the current state is "
                                },
                                {
                                    "bbox": [
                                        64,
                                        394,
                                        489,
                                        434
                                    ],
                                    "type": "inline_equation",
                                    "content": "S_{t}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        394,
                                        489,
                                        434
                                    ],
                                    "type": "text",
                                    "content": ", and actions are selected according to a stochastic policy "
                                },
                                {
                                    "bbox": [
                                        64,
                                        394,
                                        489,
                                        434
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi"
                                },
                                {
                                    "bbox": [
                                        64,
                                        394,
                                        489,
                                        434
                                    ],
                                    "type": "text",
                                    "content": ", then what is the expectation of "
                                },
                                {
                                    "bbox": [
                                        64,
                                        394,
                                        489,
                                        434
                                    ],
                                    "type": "inline_equation",
                                    "content": "R_{t + 1}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        394,
                                        489,
                                        434
                                    ],
                                    "type": "text",
                                    "content": " in terms of "
                                },
                                {
                                    "bbox": [
                                        64,
                                        394,
                                        489,
                                        434
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi"
                                },
                                {
                                    "bbox": [
                                        64,
                                        394,
                                        489,
                                        434
                                    ],
                                    "type": "text",
                                    "content": " and the four- argument function "
                                },
                                {
                                    "bbox": [
                                        64,
                                        394,
                                        489,
                                        434
                                    ],
                                    "type": "inline_equation",
                                    "content": "p"
                                },
                                {
                                    "bbox": [
                                        64,
                                        394,
                                        489,
                                        434
                                    ],
                                    "type": "text",
                                    "content": " (3.2)?"
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        64,
                        436,
                        489,
                        463
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                436,
                                489,
                                463
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        436,
                                        489,
                                        463
                                    ],
                                    "type": "text",
                                    "content": "The value function of a state "
                                },
                                {
                                    "bbox": [
                                        64,
                                        436,
                                        489,
                                        463
                                    ],
                                    "type": "inline_equation",
                                    "content": "s"
                                },
                                {
                                    "bbox": [
                                        64,
                                        436,
                                        489,
                                        463
                                    ],
                                    "type": "text",
                                    "content": " under a policy "
                                },
                                {
                                    "bbox": [
                                        64,
                                        436,
                                        489,
                                        463
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi"
                                },
                                {
                                    "bbox": [
                                        64,
                                        436,
                                        489,
                                        463
                                    ],
                                    "type": "text",
                                    "content": ", denoted "
                                },
                                {
                                    "bbox": [
                                        64,
                                        436,
                                        489,
                                        463
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}(s)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        436,
                                        489,
                                        463
                                    ],
                                    "type": "text",
                                    "content": ", is the expected return when starting in "
                                },
                                {
                                    "bbox": [
                                        64,
                                        436,
                                        489,
                                        463
                                    ],
                                    "type": "inline_equation",
                                    "content": "s"
                                },
                                {
                                    "bbox": [
                                        64,
                                        436,
                                        489,
                                        463
                                    ],
                                    "type": "text",
                                    "content": " and following "
                                },
                                {
                                    "bbox": [
                                        64,
                                        436,
                                        489,
                                        463
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi"
                                },
                                {
                                    "bbox": [
                                        64,
                                        436,
                                        489,
                                        463
                                    ],
                                    "type": "text",
                                    "content": " thereafter. For MDPs, we can define "
                                },
                                {
                                    "bbox": [
                                        64,
                                        436,
                                        489,
                                        463
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        436,
                                        489,
                                        463
                                    ],
                                    "type": "text",
                                    "content": " formally by"
                                }
                            ]
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        91,
                        471,
                        489,
                        507
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                91,
                                471,
                                489,
                                507
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        91,
                                        471,
                                        489,
                                        507
                                    ],
                                    "type": "interline_equation",
                                    "content": "v_{\\pi}(s) \\doteq \\mathbb{E}_{\\pi}[G_{t} \\mid S_{t} = s] = \\mathbb{E}_{\\pi}\\left[\\sum_{k = 0}^{\\infty} \\gamma^{k} R_{t + k + 1} \\mid S_{t} = s\\right], \\text{for all} s \\in \\mathcal{S}, \\tag{3.12}",
                                    "image_path": "42a1309a4302bbdcbd8e468747c42ce62a6c00bf1a7ec4c3dbb685fef4454835.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 6
                },
                {
                    "bbox": [
                        64,
                        516,
                        489,
                        556
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                516,
                                489,
                                556
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        516,
                                        489,
                                        556
                                    ],
                                    "type": "text",
                                    "content": "where "
                                },
                                {
                                    "bbox": [
                                        64,
                                        516,
                                        489,
                                        556
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\mathbb{E}_{\\pi}[\\cdot ]"
                                },
                                {
                                    "bbox": [
                                        64,
                                        516,
                                        489,
                                        556
                                    ],
                                    "type": "text",
                                    "content": " denotes the expected value of a random variable given that the agent follows policy "
                                },
                                {
                                    "bbox": [
                                        64,
                                        516,
                                        489,
                                        556
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi"
                                },
                                {
                                    "bbox": [
                                        64,
                                        516,
                                        489,
                                        556
                                    ],
                                    "type": "text",
                                    "content": ", and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        516,
                                        489,
                                        556
                                    ],
                                    "type": "inline_equation",
                                    "content": "t"
                                },
                                {
                                    "bbox": [
                                        64,
                                        516,
                                        489,
                                        556
                                    ],
                                    "type": "text",
                                    "content": " is any time step. Note that the value of the terminal state, if any, is always zero. We call the function "
                                },
                                {
                                    "bbox": [
                                        64,
                                        516,
                                        489,
                                        556
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        516,
                                        489,
                                        556
                                    ],
                                    "type": "text",
                                    "content": " the state- value function for policy "
                                },
                                {
                                    "bbox": [
                                        64,
                                        516,
                                        489,
                                        556
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi"
                                },
                                {
                                    "bbox": [
                                        64,
                                        516,
                                        489,
                                        556
                                    ],
                                    "type": "text",
                                    "content": "."
                                }
                            ]
                        }
                    ],
                    "index": 7
                },
                {
                    "bbox": [
                        64,
                        557,
                        489,
                        597
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                557,
                                489,
                                597
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        557,
                                        489,
                                        597
                                    ],
                                    "type": "text",
                                    "content": "Similarly, we define the value of taking action "
                                },
                                {
                                    "bbox": [
                                        64,
                                        557,
                                        489,
                                        597
                                    ],
                                    "type": "inline_equation",
                                    "content": "a"
                                },
                                {
                                    "bbox": [
                                        64,
                                        557,
                                        489,
                                        597
                                    ],
                                    "type": "text",
                                    "content": " in state "
                                },
                                {
                                    "bbox": [
                                        64,
                                        557,
                                        489,
                                        597
                                    ],
                                    "type": "inline_equation",
                                    "content": "s"
                                },
                                {
                                    "bbox": [
                                        64,
                                        557,
                                        489,
                                        597
                                    ],
                                    "type": "text",
                                    "content": " under a policy "
                                },
                                {
                                    "bbox": [
                                        64,
                                        557,
                                        489,
                                        597
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi"
                                },
                                {
                                    "bbox": [
                                        64,
                                        557,
                                        489,
                                        597
                                    ],
                                    "type": "text",
                                    "content": ", denoted "
                                },
                                {
                                    "bbox": [
                                        64,
                                        557,
                                        489,
                                        597
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{\\pi}(s,a)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        557,
                                        489,
                                        597
                                    ],
                                    "type": "text",
                                    "content": ", as the expected return starting from "
                                },
                                {
                                    "bbox": [
                                        64,
                                        557,
                                        489,
                                        597
                                    ],
                                    "type": "inline_equation",
                                    "content": "s"
                                },
                                {
                                    "bbox": [
                                        64,
                                        557,
                                        489,
                                        597
                                    ],
                                    "type": "text",
                                    "content": ", taking the action "
                                },
                                {
                                    "bbox": [
                                        64,
                                        557,
                                        489,
                                        597
                                    ],
                                    "type": "inline_equation",
                                    "content": "a"
                                },
                                {
                                    "bbox": [
                                        64,
                                        557,
                                        489,
                                        597
                                    ],
                                    "type": "text",
                                    "content": ", and thereafter following policy "
                                },
                                {
                                    "bbox": [
                                        64,
                                        557,
                                        489,
                                        597
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi"
                                },
                                {
                                    "bbox": [
                                        64,
                                        557,
                                        489,
                                        597
                                    ],
                                    "type": "text",
                                    "content": ":"
                                }
                            ]
                        }
                    ],
                    "index": 8
                },
                {
                    "bbox": [
                        91,
                        605,
                        489,
                        642
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                91,
                                605,
                                489,
                                642
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        91,
                                        605,
                                        489,
                                        642
                                    ],
                                    "type": "interline_equation",
                                    "content": "q_{\\pi}(s,a) \\doteq \\mathbb{E}_{\\pi}[G_{t} \\mid S_{t} = s, A_{t} = a] = \\mathbb{E}_{\\pi}\\left[\\sum_{k = 0}^{\\infty} \\gamma^{k} R_{t + k + 1} \\mid S_{t} = s, A_{t} = a\\right]. \\tag{3.13}",
                                    "image_path": "d37512913ae71a797c7f4fb23be63983c8eefd033c9b2d84172681987dd15cf3.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 9
                },
                {
                    "bbox": [
                        63,
                        650,
                        302,
                        664
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                63,
                                650,
                                302,
                                664
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        63,
                                        650,
                                        302,
                                        664
                                    ],
                                    "type": "text",
                                    "content": "We call "
                                },
                                {
                                    "bbox": [
                                        63,
                                        650,
                                        302,
                                        664
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        63,
                                        650,
                                        302,
                                        664
                                    ],
                                    "type": "text",
                                    "content": " the action- value function for policy "
                                },
                                {
                                    "bbox": [
                                        63,
                                        650,
                                        302,
                                        664
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi"
                                },
                                {
                                    "bbox": [
                                        63,
                                        650,
                                        302,
                                        664
                                    ],
                                    "type": "text",
                                    "content": "."
                                }
                            ]
                        }
                    ],
                    "index": 10
                },
                {
                    "bbox": [
                        64,
                        668,
                        357,
                        682
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                668,
                                357,
                                682
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        668,
                                        357,
                                        682
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.12 Give an equation for "
                                },
                                {
                                    "bbox": [
                                        64,
                                        668,
                                        357,
                                        682
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        668,
                                        357,
                                        682
                                    ],
                                    "type": "text",
                                    "content": " in terms of "
                                },
                                {
                                    "bbox": [
                                        64,
                                        668,
                                        357,
                                        682
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        668,
                                        357,
                                        682
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        668,
                                        357,
                                        682
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi"
                                },
                                {
                                    "bbox": [
                                        64,
                                        668,
                                        357,
                                        682
                                    ],
                                    "type": "text",
                                    "content": "."
                                }
                            ]
                        }
                    ],
                    "index": 11
                },
                {
                    "bbox": [
                        64,
                        686,
                        447,
                        699
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                686,
                                447,
                                699
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        686,
                                        447,
                                        699
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.13 Give an equation for "
                                },
                                {
                                    "bbox": [
                                        64,
                                        686,
                                        447,
                                        699
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        686,
                                        447,
                                        699
                                    ],
                                    "type": "text",
                                    "content": " in terms of "
                                },
                                {
                                    "bbox": [
                                        64,
                                        686,
                                        447,
                                        699
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        686,
                                        447,
                                        699
                                    ],
                                    "type": "text",
                                    "content": " and the four- argument "
                                },
                                {
                                    "bbox": [
                                        64,
                                        686,
                                        447,
                                        699
                                    ],
                                    "type": "inline_equation",
                                    "content": "p"
                                },
                                {
                                    "bbox": [
                                        64,
                                        686,
                                        447,
                                        699
                                    ],
                                    "type": "text",
                                    "content": "."
                                }
                            ]
                        }
                    ],
                    "index": 12
                },
                {
                    "bbox": [
                        64,
                        700,
                        490,
                        754
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                700,
                                490,
                                754
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        700,
                                        490,
                                        754
                                    ],
                                    "type": "text",
                                    "content": "The value functions "
                                },
                                {
                                    "bbox": [
                                        64,
                                        700,
                                        490,
                                        754
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        700,
                                        490,
                                        754
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        700,
                                        490,
                                        754
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        700,
                                        490,
                                        754
                                    ],
                                    "type": "text",
                                    "content": " can be estimated from experience. For example, if an agent follows policy "
                                },
                                {
                                    "bbox": [
                                        64,
                                        700,
                                        490,
                                        754
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi"
                                },
                                {
                                    "bbox": [
                                        64,
                                        700,
                                        490,
                                        754
                                    ],
                                    "type": "text",
                                    "content": " and maintains an average, for each state encountered, of the actual returns that have followed that state, then the average will converge to the state's value, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        700,
                                        490,
                                        754
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}(s)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        700,
                                        490,
                                        754
                                    ],
                                    "type": "text",
                                    "content": ", as the number of times that state is encountered approaches infinity. If separate"
                                }
                            ]
                        }
                    ],
                    "index": 13
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 11
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        104,
                        140,
                        530,
                        273
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                140,
                                530,
                                273
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        140,
                                        530,
                                        273
                                    ],
                                    "type": "text",
                                    "content": "averages are kept for each action taken in each state, then these averages will similarly converge to the action values, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        140,
                                        530,
                                        273
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{\\pi}(s,a)"
                                },
                                {
                                    "bbox": [
                                        104,
                                        140,
                                        530,
                                        273
                                    ],
                                    "type": "text",
                                    "content": ". We call estimation methods of this kind Monte Carlo methods because they involve averaging over many random samples of actual returns. These kinds of methods are presented in Chapter 5. Of course, if there are very many states, then it may not be practical to keep separate averages for each state individually. Instead, the agent would have to maintain "
                                },
                                {
                                    "bbox": [
                                        104,
                                        140,
                                        530,
                                        273
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        140,
                                        530,
                                        273
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        104,
                                        140,
                                        530,
                                        273
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        140,
                                        530,
                                        273
                                    ],
                                    "type": "text",
                                    "content": " as parameterized functions (with fewer parameters than states) and adjust the parameters to better match the observed returns. This can also produce accurate estimates, although much depends on the nature of the parameterized function approximator. These possibilities are discussed in Part II of the book."
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        104,
                        275,
                        530,
                        341
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                275,
                                530,
                                341
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        275,
                                        530,
                                        341
                                    ],
                                    "type": "text",
                                    "content": "A fundamental property of value functions used throughout reinforcement learning and dynamic programming is that they satisfy recursive relationships similar to that which we have already established for the return (3.9). For any policy "
                                },
                                {
                                    "bbox": [
                                        104,
                                        275,
                                        530,
                                        341
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi"
                                },
                                {
                                    "bbox": [
                                        104,
                                        275,
                                        530,
                                        341
                                    ],
                                    "type": "text",
                                    "content": " and any state "
                                },
                                {
                                    "bbox": [
                                        104,
                                        275,
                                        530,
                                        341
                                    ],
                                    "type": "inline_equation",
                                    "content": "s"
                                },
                                {
                                    "bbox": [
                                        104,
                                        275,
                                        530,
                                        341
                                    ],
                                    "type": "text",
                                    "content": ", the following consistency condition holds between the value of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        275,
                                        530,
                                        341
                                    ],
                                    "type": "inline_equation",
                                    "content": "s"
                                },
                                {
                                    "bbox": [
                                        104,
                                        275,
                                        530,
                                        341
                                    ],
                                    "type": "text",
                                    "content": " and the value of its possible successor states:"
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        130,
                        345,
                        528,
                        443
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                130,
                                345,
                                528,
                                443
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        130,
                                        345,
                                        528,
                                        443
                                    ],
                                    "type": "interline_equation",
                                    "content": "\\begin{array}{r l} & {v_{\\pi}(s)\\doteq \\mathbb{E}_{\\pi}[G_{t}\\mid S_{t} = s]}\\\\ & {\\qquad = \\mathbb{E}_{\\pi}[R_{t + 1} + \\gamma G_{t + 1}\\mid S_{t} = s]}\\\\ & {\\qquad = \\sum_{a}\\pi (a|s)\\sum_{s^{\\prime}}\\sum_{r}p(s^{\\prime},r|s,a)\\Big[r + \\gamma \\mathbb{E}_{\\pi}[G_{t + 1}|S_{t + 1} = s^{\\prime}]\\Big]}\\\\ & {\\qquad = \\sum_{a}\\pi (a|s)\\sum_{s^{\\prime},r}p(s^{\\prime},r|s,a)\\Big[r + \\gamma v_{\\pi}(s^{\\prime})\\Big],\\quad \\mathrm{for~all~}s\\in \\mathbb{S},} \\end{array} \\tag{by (3.9)}",
                                    "image_path": "a3417b66fea76980c8fb37b2674ead57d86d17c815561746f8f362b846f2297a.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        104,
                        447,
                        531,
                        566
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                447,
                                531,
                                566
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "text",
                                    "content": "where it is implicit that the actions, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "inline_equation",
                                    "content": "a"
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "text",
                                    "content": ", are taken from the set "
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\mathcal{A}(s)"
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "text",
                                    "content": ", that the next states, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "inline_equation",
                                    "content": "s^{\\prime}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "text",
                                    "content": ", are taken from the set "
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\mathcal{S}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "text",
                                    "content": " (or from "
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\mathbb{S}^{+}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "text",
                                    "content": " in the case of an episodic problem), and that the rewards, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "inline_equation",
                                    "content": "r"
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "text",
                                    "content": ", are taken from the set "
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\mathcal{R}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "text",
                                    "content": ". Note also how in the last equation we have merged the two sums, one over all the values of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "inline_equation",
                                    "content": "s^{\\prime}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "text",
                                    "content": " and the other over all the values of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "inline_equation",
                                    "content": "r"
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "text",
                                    "content": ", into one sum over all the possible values of both. We use this kind of merged sum often to simplify formulas. Note how the final expression can be read easily as an expected value. It is really a sum over all values of the three variables, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "inline_equation",
                                    "content": "a"
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "text",
                                    "content": ", "
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "inline_equation",
                                    "content": "s^{\\prime}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "text",
                                    "content": ", and "
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "inline_equation",
                                    "content": "r"
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "text",
                                    "content": ". For each triple, we compute its probability, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi (a|s)p(s^{\\prime},r|s,a)"
                                },
                                {
                                    "bbox": [
                                        104,
                                        447,
                                        531,
                                        566
                                    ],
                                    "type": "text",
                                    "content": ", weight the quantity in brackets by that probability, then sum over all possibilities to get an expected value."
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        104,
                        568,
                        415,
                        673
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                568,
                                415,
                                673
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        568,
                                        415,
                                        673
                                    ],
                                    "type": "text",
                                    "content": "Equation (3.14) is the Bellman equation for "
                                },
                                {
                                    "bbox": [
                                        104,
                                        568,
                                        415,
                                        673
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        568,
                                        415,
                                        673
                                    ],
                                    "type": "text",
                                    "content": ". It expresses a relationship between the value of a state and the values of its successor states. Think of looking ahead from a state to its possible successor states, as suggested by the diagram to the right. Each open circle represents a state and each solid circle represents a state- action pair. Starting from state "
                                },
                                {
                                    "bbox": [
                                        104,
                                        568,
                                        415,
                                        673
                                    ],
                                    "type": "inline_equation",
                                    "content": "s"
                                },
                                {
                                    "bbox": [
                                        104,
                                        568,
                                        415,
                                        673
                                    ],
                                    "type": "text",
                                    "content": ", the root node at the top, the agent could take any of some set of actionsâ€”three are shown in the diagramâ€”based on its policy "
                                },
                                {
                                    "bbox": [
                                        104,
                                        568,
                                        415,
                                        673
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi"
                                },
                                {
                                    "bbox": [
                                        104,
                                        568,
                                        415,
                                        673
                                    ],
                                    "type": "text",
                                    "content": ". From each of these, the environment could respond with one of several next states, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        568,
                                        415,
                                        673
                                    ],
                                    "type": "inline_equation",
                                    "content": "s^{\\prime}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        568,
                                        415,
                                        673
                                    ],
                                    "type": "text",
                                    "content": " (two are shown in the figure), along with a reward, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        568,
                                        415,
                                        673
                                    ],
                                    "type": "inline_equation",
                                    "content": "r"
                                },
                                {
                                    "bbox": [
                                        104,
                                        568,
                                        415,
                                        673
                                    ],
                                    "type": "text",
                                    "content": ", depending on its dynamics given by the function "
                                },
                                {
                                    "bbox": [
                                        104,
                                        568,
                                        415,
                                        673
                                    ],
                                    "type": "inline_equation",
                                    "content": "p"
                                },
                                {
                                    "bbox": [
                                        104,
                                        568,
                                        415,
                                        673
                                    ],
                                    "type": "text",
                                    "content": ". The Bellman equation (3.14) averages over all the possibilities, weighting each by its probability of occurring. It states that the value of the start state must equal the (discounted) value of the expected next state, plus the reward expected along the way."
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "type": "image",
                    "bbox": [
                        421,
                        578,
                        525,
                        653
                    ],
                    "blocks": [
                        {
                            "bbox": [
                                421,
                                578,
                                525,
                                653
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        421,
                                        578,
                                        525,
                                        653
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                421,
                                                578,
                                                525,
                                                653
                                            ],
                                            "type": "image",
                                            "image_path": "b12e972cc6b2c2a49f81f47c0d05876f2985dd86a8e24fe985a7d2f9e3bdad61.jpg"
                                        }
                                    ]
                                }
                            ],
                            "index": 5,
                            "type": "image_body"
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        421,
                        655,
                        525,
                        666
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                421,
                                655,
                                525,
                                666
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        421,
                                        655,
                                        525,
                                        666
                                    ],
                                    "type": "text",
                                    "content": "Backup diagram for "
                                },
                                {
                                    "bbox": [
                                        421,
                                        655,
                                        525,
                                        666
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}"
                                }
                            ]
                        }
                    ],
                    "index": 6
                },
                {
                    "bbox": [
                        104,
                        673,
                        530,
                        740
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                673,
                                530,
                                740
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        673,
                                        530,
                                        740
                                    ],
                                    "type": "text",
                                    "content": "each of these, the environment could respond with one of several next states, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        673,
                                        530,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "s^{\\prime}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        673,
                                        530,
                                        740
                                    ],
                                    "type": "text",
                                    "content": " (two are shown in the figure), along with a reward, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        673,
                                        530,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "r"
                                },
                                {
                                    "bbox": [
                                        104,
                                        673,
                                        530,
                                        740
                                    ],
                                    "type": "text",
                                    "content": " , depending on its dynamics given by the function "
                                },
                                {
                                    "bbox": [
                                        104,
                                        673,
                                        530,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "p"
                                },
                                {
                                    "bbox": [
                                        104,
                                        673,
                                        530,
                                        740
                                    ],
                                    "type": "text",
                                    "content": " . The Bellman equation (3.14) averages over all the possibilities, weighting each by its probability of occurring. It states that the value of the start state must equal the (discounted) value of the expected next state, plus the reward expected along the way."
                                }
                            ]
                        }
                    ],
                    "index": 7
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 12
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        64,
                        141,
                        489,
                        273
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                141,
                                489,
                                273
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        141,
                                        489,
                                        273
                                    ],
                                    "type": "text",
                                    "content": "The value function "
                                },
                                {
                                    "bbox": [
                                        64,
                                        141,
                                        489,
                                        273
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        141,
                                        489,
                                        273
                                    ],
                                    "type": "text",
                                    "content": " is the unique solution to its Bellman equation. We show in subsequent chapters how this Bellman equation forms the basis of a number of ways to compute, approximate, and learn "
                                },
                                {
                                    "bbox": [
                                        64,
                                        141,
                                        489,
                                        273
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        141,
                                        489,
                                        273
                                    ],
                                    "type": "text",
                                    "content": ". We call diagrams like that above backup diagrams because they diagram relationships that form the basis of the update or backup operations that are at the heart of reinforcement learning methods. These operations transfer value information back to a state (or a state- action pair) from its successor states (or state- action pairs). We use backup diagrams throughout the book to provide graphical summaries of the algorithms we discuss. (Note that, unlike transition graphs, the state nodes of backup diagrams do not necessarily represent distinct states; for example, a state might be its own successor.)"
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        64,
                        279,
                        489,
                        386
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                279,
                                489,
                                386
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        279,
                                        489,
                                        386
                                    ],
                                    "type": "text",
                                    "content": "Example 3.5: Gridworld Figure 3.2 (left) shows a rectangular gridworld representation of a simple finite MDP. The cells of the grid correspond to the states of the environment. At each cell, four actions are possible: north, south, east, and west, which deterministically cause the agent to move one cell in the respective direction on the grid. Actions that would take the agent off the grid leave its location unchanged, but also result in a reward of "
                                },
                                {
                                    "bbox": [
                                        64,
                                        279,
                                        489,
                                        386
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 1"
                                },
                                {
                                    "bbox": [
                                        64,
                                        279,
                                        489,
                                        386
                                    ],
                                    "type": "text",
                                    "content": ". Other actions result in a reward of 0, except those that move the agent out of the special states A and B. From state A, all four actions yield a reward of "
                                },
                                {
                                    "bbox": [
                                        64,
                                        279,
                                        489,
                                        386
                                    ],
                                    "type": "inline_equation",
                                    "content": "+10"
                                },
                                {
                                    "bbox": [
                                        64,
                                        279,
                                        489,
                                        386
                                    ],
                                    "type": "text",
                                    "content": " and take the agent to "
                                },
                                {
                                    "bbox": [
                                        64,
                                        279,
                                        489,
                                        386
                                    ],
                                    "type": "inline_equation",
                                    "content": "A'"
                                },
                                {
                                    "bbox": [
                                        64,
                                        279,
                                        489,
                                        386
                                    ],
                                    "type": "text",
                                    "content": ". From state B, all actions yield a reward of "
                                },
                                {
                                    "bbox": [
                                        64,
                                        279,
                                        489,
                                        386
                                    ],
                                    "type": "inline_equation",
                                    "content": "+5"
                                },
                                {
                                    "bbox": [
                                        64,
                                        279,
                                        489,
                                        386
                                    ],
                                    "type": "text",
                                    "content": " and take the agent to "
                                },
                                {
                                    "bbox": [
                                        64,
                                        279,
                                        489,
                                        386
                                    ],
                                    "type": "inline_equation",
                                    "content": "B'"
                                },
                                {
                                    "bbox": [
                                        64,
                                        279,
                                        489,
                                        386
                                    ],
                                    "type": "text",
                                    "content": "."
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "type": "image",
                    "bbox": [
                        138,
                        405,
                        295,
                        494
                    ],
                    "blocks": [
                        {
                            "bbox": [
                                138,
                                405,
                                295,
                                494
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        138,
                                        405,
                                        295,
                                        494
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                138,
                                                405,
                                                295,
                                                494
                                            ],
                                            "type": "image",
                                            "image_path": "59d56d1375d332da705fb34f589f0ed4d13f71c0adc81c2827ba1147a5898243.jpg"
                                        }
                                    ]
                                }
                            ],
                            "index": 2,
                            "type": "image_body"
                        },
                        {
                            "bbox": [
                                64,
                                506,
                                489,
                                531
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        64,
                                        506,
                                        489,
                                        531
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                64,
                                                506,
                                                489,
                                                531
                                            ],
                                            "type": "text",
                                            "content": "Figure 3.2: Gridworld example: exceptional reward dynamics (left) and state-value function for the equiprobable random policy (right)."
                                        }
                                    ]
                                }
                            ],
                            "index": 3,
                            "type": "image_caption"
                        }
                    ],
                    "index": 2
                },
                {
                    "type": "image",
                    "bbox": [
                        327,
                        405,
                        415,
                        494
                    ],
                    "blocks": [
                        {
                            "bbox": [
                                327,
                                405,
                                415,
                                494
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        327,
                                        405,
                                        415,
                                        494
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                327,
                                                405,
                                                415,
                                                494
                                            ],
                                            "type": "image",
                                            "image_path": "0a6d74736339f0d1697431d0fac91bd895feb4337fb16877e31d3a527a7bbe11.jpg"
                                        }
                                    ]
                                }
                            ],
                            "index": 4,
                            "type": "image_body"
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        64,
                        548,
                        489,
                        695
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                548,
                                489,
                                695
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        548,
                                        489,
                                        695
                                    ],
                                    "type": "text",
                                    "content": "Suppose the agent selects all four actions with equal probability in all states. Figure 3.2 (right) shows the value function, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        548,
                                        489,
                                        695
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        548,
                                        489,
                                        695
                                    ],
                                    "type": "text",
                                    "content": ", for this policy, for the discounted reward case with "
                                },
                                {
                                    "bbox": [
                                        64,
                                        548,
                                        489,
                                        695
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\gamma = 0.9"
                                },
                                {
                                    "bbox": [
                                        64,
                                        548,
                                        489,
                                        695
                                    ],
                                    "type": "text",
                                    "content": ". This value function was computed by solving the system of linear equations (3.14). Notice the negative values near the lower edge; these are the result of the high probability of hitting the edge of the grid there under the random policy. State A is the best state to be in under this policy. Note that A's expected return is less than its immediate reward of 10, because from A the agent is taken to state "
                                },
                                {
                                    "bbox": [
                                        64,
                                        548,
                                        489,
                                        695
                                    ],
                                    "type": "inline_equation",
                                    "content": "A'"
                                },
                                {
                                    "bbox": [
                                        64,
                                        548,
                                        489,
                                        695
                                    ],
                                    "type": "text",
                                    "content": " from which it is likely to run into the edge of the grid. State B, on the other hand, is valued more than its immediate reward of 5, because from B the agent is taken to "
                                },
                                {
                                    "bbox": [
                                        64,
                                        548,
                                        489,
                                        695
                                    ],
                                    "type": "inline_equation",
                                    "content": "B'"
                                },
                                {
                                    "bbox": [
                                        64,
                                        548,
                                        489,
                                        695
                                    ],
                                    "type": "text",
                                    "content": " which has a positive value. From "
                                },
                                {
                                    "bbox": [
                                        64,
                                        548,
                                        489,
                                        695
                                    ],
                                    "type": "inline_equation",
                                    "content": "B'"
                                },
                                {
                                    "bbox": [
                                        64,
                                        548,
                                        489,
                                        695
                                    ],
                                    "type": "text",
                                    "content": " the expected penalty (negative reward) for possibly running into an edge is more than compensated for by the expected gain for possibly stumbling onto A or B."
                                }
                            ]
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        64,
                        701,
                        489,
                        755
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                701,
                                489,
                                755
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        701,
                                        489,
                                        755
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.14 The Bellman equation (3.14) must hold for each state for the value function "
                                },
                                {
                                    "bbox": [
                                        64,
                                        701,
                                        489,
                                        755
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        701,
                                        489,
                                        755
                                    ],
                                    "type": "text",
                                    "content": " shown in Figure 3.2 (right) of Example 3.5. Show numerically that this equation holds for the center state, valued at "
                                },
                                {
                                    "bbox": [
                                        64,
                                        701,
                                        489,
                                        755
                                    ],
                                    "type": "inline_equation",
                                    "content": "+0.7"
                                },
                                {
                                    "bbox": [
                                        64,
                                        701,
                                        489,
                                        755
                                    ],
                                    "type": "text",
                                    "content": ", with respect to its four neighboring states, valued at "
                                },
                                {
                                    "bbox": [
                                        64,
                                        701,
                                        489,
                                        755
                                    ],
                                    "type": "inline_equation",
                                    "content": "+2.3"
                                },
                                {
                                    "bbox": [
                                        64,
                                        701,
                                        489,
                                        755
                                    ],
                                    "type": "text",
                                    "content": ", "
                                },
                                {
                                    "bbox": [
                                        64,
                                        701,
                                        489,
                                        755
                                    ],
                                    "type": "inline_equation",
                                    "content": "+0.4"
                                },
                                {
                                    "bbox": [
                                        64,
                                        701,
                                        489,
                                        755
                                    ],
                                    "type": "text",
                                    "content": ", "
                                },
                                {
                                    "bbox": [
                                        64,
                                        701,
                                        489,
                                        755
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 0.4"
                                },
                                {
                                    "bbox": [
                                        64,
                                        701,
                                        489,
                                        755
                                    ],
                                    "type": "text",
                                    "content": ", and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        701,
                                        489,
                                        755
                                    ],
                                    "type": "inline_equation",
                                    "content": "+0.7"
                                },
                                {
                                    "bbox": [
                                        64,
                                        701,
                                        489,
                                        755
                                    ],
                                    "type": "text",
                                    "content": ". (These numbers are accurate only to one decimal place.) "
                                },
                                {
                                    "bbox": [
                                        64,
                                        701,
                                        489,
                                        755
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\square"
                                }
                            ]
                        }
                    ],
                    "index": 6
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 13
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        104,
                        141,
                        530,
                        220
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                141,
                                530,
                                220
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        220
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.15 In the gridworld example, rewards are positive for goals, negative for running into the edge of the world, and zero the rest of the time. Are the signs of these rewards important, or only the intervals between them? Prove, using (3.8), that adding a constant "
                                },
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        220
                                    ],
                                    "type": "inline_equation",
                                    "content": "c"
                                },
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        220
                                    ],
                                    "type": "text",
                                    "content": " to all the rewards adds a constant, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        220
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{c}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        220
                                    ],
                                    "type": "text",
                                    "content": ", to the values of all states, and thus does not affect the relative values of any states under any policies. What is "
                                },
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        220
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{c}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        220
                                    ],
                                    "type": "text",
                                    "content": " in terms of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        220
                                    ],
                                    "type": "inline_equation",
                                    "content": "c"
                                },
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        220
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        220
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\gamma"
                                },
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        220
                                    ],
                                    "type": "text",
                                    "content": "?"
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        104,
                        224,
                        530,
                        264
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                224,
                                530,
                                264
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        224,
                                        530,
                                        264
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.16 Now consider adding a constant "
                                },
                                {
                                    "bbox": [
                                        104,
                                        224,
                                        530,
                                        264
                                    ],
                                    "type": "inline_equation",
                                    "content": "c"
                                },
                                {
                                    "bbox": [
                                        104,
                                        224,
                                        530,
                                        264
                                    ],
                                    "type": "text",
                                    "content": " to all the rewards in an episodic task, such as maze running. Would this have any effect, or would it leave the task unchanged as in the continuing task above? Why or why not? Give an example."
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        104,
                        268,
                        530,
                        362
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                268,
                                530,
                                362
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        268,
                                        530,
                                        362
                                    ],
                                    "type": "text",
                                    "content": "Example 3.6: Golf To formulate playing a hole of golf as a reinforcement learning task, we count a penalty (negative reward) of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        268,
                                        530,
                                        362
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 1"
                                },
                                {
                                    "bbox": [
                                        104,
                                        268,
                                        530,
                                        362
                                    ],
                                    "type": "text",
                                    "content": " for each stroke until we hit the ball into the hole. The state is the location of the ball. The value of a state is the negative of the number of strokes to the hole from that location. Our actions are how we aim and swing at the ball, of course, and which club we select. Let us take the former as given and consider just the choice of club, which we assume is either a putter or a driver. The upper part of Figure 3.3 shows a possible state- value function, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        268,
                                        530,
                                        362
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\mathrm{putt}}(s)"
                                },
                                {
                                    "bbox": [
                                        104,
                                        268,
                                        530,
                                        362
                                    ],
                                    "type": "text",
                                    "content": ", for the policy that always uses the putter. The terminal state in- the- hole has a value of 0. From anywhere on the green we assume we can make a putt; these states have value "
                                },
                                {
                                    "bbox": [
                                        104,
                                        268,
                                        530,
                                        362
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 1"
                                },
                                {
                                    "bbox": [
                                        104,
                                        268,
                                        530,
                                        362
                                    ],
                                    "type": "text",
                                    "content": ". Off the green we cannot reach the hole by putting, and the value is lower. If we can reach the green from a state by putting, then that state must have value one less than the green's value, that is, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        268,
                                        530,
                                        362
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 2"
                                },
                                {
                                    "bbox": [
                                        104,
                                        268,
                                        530,
                                        362
                                    ],
                                    "type": "text",
                                    "content": ". For simplicity, let us assume we can putt very precisely and deterministically, but with a limited range. This gives us the sharp contour line labeled "
                                },
                                {
                                    "bbox": [
                                        104,
                                        268,
                                        530,
                                        362
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 2"
                                },
                                {
                                    "bbox": [
                                        104,
                                        268,
                                        530,
                                        362
                                    ],
                                    "type": "text",
                                    "content": " in the figure; all locations between that line and the green require exactly two strokes to complete the hole. Similarly, any location within putting range of the "
                                },
                                {
                                    "bbox": [
                                        104,
                                        268,
                                        530,
                                        362
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 2"
                                },
                                {
                                    "bbox": [
                                        104,
                                        268,
                                        530,
                                        362
                                    ],
                                    "type": "text",
                                    "content": " contour line must have a value of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        268,
                                        530,
                                        362
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 3"
                                },
                                {
                                    "bbox": [
                                        104,
                                        268,
                                        530,
                                        362
                                    ],
                                    "type": "text",
                                    "content": ", and so on to get all the contour lines shown in the figure. Putting doesn't get us out of sand traps, so they have a value of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        268,
                                        530,
                                        362
                                    ],
                                    "type": "inline_equation",
                                    "content": "- \\infty"
                                },
                                {
                                    "bbox": [
                                        104,
                                        268,
                                        530,
                                        362
                                    ],
                                    "type": "text",
                                    "content": ". Overall, it takes us six strokes to get from the tee to the hole by putting."
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        104,
                        362,
                        301,
                        666
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                362,
                                301,
                                666
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        362,
                                        301,
                                        666
                                    ],
                                    "type": "text",
                                    "content": "always uses the putter. The terminal state in- the- hole has a value of 0. From anywhere on the green we assume we can make a putt; these states have value "
                                },
                                {
                                    "bbox": [
                                        104,
                                        362,
                                        301,
                                        666
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 1"
                                },
                                {
                                    "bbox": [
                                        104,
                                        362,
                                        301,
                                        666
                                    ],
                                    "type": "text",
                                    "content": " Off the green we cannot reach the hole by putting, and the value is lower. If we can reach the green from a state by putting, then that state must have value one less than the green's value, that is, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        362,
                                        301,
                                        666
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 2"
                                },
                                {
                                    "bbox": [
                                        104,
                                        362,
                                        301,
                                        666
                                    ],
                                    "type": "text",
                                    "content": " . For simplicity, let us assume we can putt very precisely and deterministically, but with a limited range. This gives us the sharp contour line labeled "
                                },
                                {
                                    "bbox": [
                                        104,
                                        362,
                                        301,
                                        666
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 2"
                                },
                                {
                                    "bbox": [
                                        104,
                                        362,
                                        301,
                                        666
                                    ],
                                    "type": "text",
                                    "content": " in the figure; all locations between that line and the green require exactly two strokes to complete the hole. Similarly, any location within putting range of the "
                                },
                                {
                                    "bbox": [
                                        104,
                                        362,
                                        301,
                                        666
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 2"
                                },
                                {
                                    "bbox": [
                                        104,
                                        362,
                                        301,
                                        666
                                    ],
                                    "type": "text",
                                    "content": " contour line must have a value of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        362,
                                        301,
                                        666
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 3"
                                },
                                {
                                    "bbox": [
                                        104,
                                        362,
                                        301,
                                        666
                                    ],
                                    "type": "text",
                                    "content": " , and so on to get all the contour lines shown in the figure. Putting doesn't get us out of sand traps, so they have a value of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        362,
                                        301,
                                        666
                                    ],
                                    "type": "inline_equation",
                                    "content": "- \\infty"
                                },
                                {
                                    "bbox": [
                                        104,
                                        362,
                                        301,
                                        666
                                    ],
                                    "type": "text",
                                    "content": " . Overall, it takes us six strokes to get from the tee to the hole by putting."
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "type": "image",
                    "bbox": [
                        311,
                        378,
                        529,
                        612
                    ],
                    "blocks": [
                        {
                            "bbox": [
                                311,
                                378,
                                529,
                                612
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        311,
                                        378,
                                        529,
                                        612
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                311,
                                                378,
                                                529,
                                                612
                                            ],
                                            "type": "image",
                                            "image_path": "3f22a3b1156a0e172435ab25ce9aabd0a617a8dff3a5c9873a26e009480313b0.jpg"
                                        }
                                    ]
                                }
                            ],
                            "index": 4,
                            "type": "image_body"
                        },
                        {
                            "bbox": [
                                309,
                                621,
                                530,
                                658
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        309,
                                        621,
                                        530,
                                        658
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                309,
                                                621,
                                                530,
                                                658
                                            ],
                                            "type": "text",
                                            "content": "Figure 3.3: A golf example: the state-value function for putting (upper) and the optimal action-value function for using the driver (lower)."
                                        }
                                    ]
                                }
                            ],
                            "index": 5,
                            "type": "image_caption"
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        104,
                        671,
                        443,
                        750
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                671,
                                443,
                                750
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        671,
                                        443,
                                        750
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.17 What is the Bellman equation for action values, that is, for "
                                },
                                {
                                    "bbox": [
                                        104,
                                        671,
                                        443,
                                        750
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        671,
                                        443,
                                        750
                                    ],
                                    "type": "text",
                                    "content": "? It must give the action value "
                                },
                                {
                                    "bbox": [
                                        104,
                                        671,
                                        443,
                                        750
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{\\pi}(s, a)"
                                },
                                {
                                    "bbox": [
                                        104,
                                        671,
                                        443,
                                        750
                                    ],
                                    "type": "text",
                                    "content": " in terms of the action values, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        671,
                                        443,
                                        750
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{\\pi}(s', a')"
                                },
                                {
                                    "bbox": [
                                        104,
                                        671,
                                        443,
                                        750
                                    ],
                                    "type": "text",
                                    "content": ", of possible successors to the state- action pair "
                                },
                                {
                                    "bbox": [
                                        104,
                                        671,
                                        443,
                                        750
                                    ],
                                    "type": "inline_equation",
                                    "content": "(s, a)"
                                },
                                {
                                    "bbox": [
                                        104,
                                        671,
                                        443,
                                        750
                                    ],
                                    "type": "text",
                                    "content": ". Hint: The backup diagram to the right corresponds to this equation. Show the sequence of equations analogous to (3.14), but for action values."
                                }
                            ]
                        }
                    ],
                    "index": 6
                },
                {
                    "type": "image",
                    "bbox": [
                        449,
                        664,
                        528,
                        750
                    ],
                    "blocks": [
                        {
                            "bbox": [
                                449,
                                664,
                                528,
                                750
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        449,
                                        664,
                                        528,
                                        750
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                449,
                                                664,
                                                528,
                                                750
                                            ],
                                            "type": "image",
                                            "image_path": "ab56e394ce3494133a643184ba4c92c458364065c8399340023b9e39e2e876d0.jpg"
                                        }
                                    ]
                                }
                            ],
                            "index": 7,
                            "type": "image_body"
                        }
                    ],
                    "index": 7
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 14
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        64,
                        140,
                        489,
                        193
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                140,
                                489,
                                193
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        140,
                                        489,
                                        193
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.18 The value of a state depends on the values of the actions possible in that state and on how likely each action is to be taken under the current policy. We can think of this in terms of a small backup diagram rooted at the state and considering each possible action:"
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "type": "image",
                    "bbox": [
                        136,
                        196,
                        418,
                        250
                    ],
                    "blocks": [
                        {
                            "bbox": [
                                136,
                                196,
                                418,
                                250
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        136,
                                        196,
                                        418,
                                        250
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                136,
                                                196,
                                                418,
                                                250
                                            ],
                                            "type": "image",
                                            "image_path": "d6d8097dbe9b7d6aa633db099e1a206864f7004ef966969668ddc9a23503f487.jpg"
                                        }
                                    ]
                                }
                            ],
                            "index": 1,
                            "type": "image_body"
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        64,
                        253,
                        489,
                        320
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                253,
                                489,
                                320
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        253,
                                        489,
                                        320
                                    ],
                                    "type": "text",
                                    "content": "Give the equation corresponding to this intuition and diagram for the value at the root node, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        253,
                                        489,
                                        320
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}(s)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        253,
                                        489,
                                        320
                                    ],
                                    "type": "text",
                                    "content": " , in terms of the value at the expected leaf node, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        253,
                                        489,
                                        320
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{\\pi}(s,a)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        253,
                                        489,
                                        320
                                    ],
                                    "type": "text",
                                    "content": " , given "
                                },
                                {
                                    "bbox": [
                                        64,
                                        253,
                                        489,
                                        320
                                    ],
                                    "type": "inline_equation",
                                    "content": "S_{t} = s"
                                },
                                {
                                    "bbox": [
                                        64,
                                        253,
                                        489,
                                        320
                                    ],
                                    "type": "text",
                                    "content": " . This equation should include an expectation conditioned on following the policy, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        253,
                                        489,
                                        320
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi"
                                },
                                {
                                    "bbox": [
                                        64,
                                        253,
                                        489,
                                        320
                                    ],
                                    "type": "text",
                                    "content": " . Then give a second equation in which the expected value is written out explicitly in terms of "
                                },
                                {
                                    "bbox": [
                                        64,
                                        253,
                                        489,
                                        320
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi (a|s)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        253,
                                        489,
                                        320
                                    ],
                                    "type": "text",
                                    "content": " such that no expected value notation appears in the equation."
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        64,
                        324,
                        489,
                        377
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                324,
                                489,
                                377
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        324,
                                        489,
                                        377
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.19 The value of an action, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        324,
                                        489,
                                        377
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{\\pi}(s,a)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        324,
                                        489,
                                        377
                                    ],
                                    "type": "text",
                                    "content": " , depends on the expected next reward and the expected sum of the remaining rewards. Again we can think of this in terms of a small backup diagram, this one rooted at an action (state- action pair) and branching to the possible next states:"
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "type": "image",
                    "bbox": [
                        164,
                        378,
                        390,
                        439
                    ],
                    "blocks": [
                        {
                            "bbox": [
                                164,
                                378,
                                390,
                                439
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        164,
                                        378,
                                        390,
                                        439
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                164,
                                                378,
                                                390,
                                                439
                                            ],
                                            "type": "image",
                                            "image_path": "1f3ab6b0bc3d9a28cbfd7599efa997d4c0314b9912412fe6dfd46c8aa3c998b8.jpg"
                                        }
                                    ]
                                }
                            ],
                            "index": 4,
                            "type": "image_body"
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        64,
                        442,
                        490,
                        522
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                442,
                                490,
                                522
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        442,
                                        490,
                                        522
                                    ],
                                    "type": "text",
                                    "content": "Give the equation corresponding to this intuition and diagram for the action value, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        442,
                                        490,
                                        522
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{\\pi}(s,a)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        442,
                                        490,
                                        522
                                    ],
                                    "type": "text",
                                    "content": " , in terms of the expected next reward, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        442,
                                        490,
                                        522
                                    ],
                                    "type": "inline_equation",
                                    "content": "R_{t + 1}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        442,
                                        490,
                                        522
                                    ],
                                    "type": "text",
                                    "content": " , and the expected next state value, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        442,
                                        490,
                                        522
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}(S_{t + 1})"
                                },
                                {
                                    "bbox": [
                                        64,
                                        442,
                                        490,
                                        522
                                    ],
                                    "type": "text",
                                    "content": " , given that "
                                },
                                {
                                    "bbox": [
                                        64,
                                        442,
                                        490,
                                        522
                                    ],
                                    "type": "inline_equation",
                                    "content": "S_{t} = s"
                                },
                                {
                                    "bbox": [
                                        64,
                                        442,
                                        490,
                                        522
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        442,
                                        490,
                                        522
                                    ],
                                    "type": "inline_equation",
                                    "content": "A_{t} = a"
                                },
                                {
                                    "bbox": [
                                        64,
                                        442,
                                        490,
                                        522
                                    ],
                                    "type": "text",
                                    "content": " . This equation should include an expectation but not one conditioned on following the policy. Then give a second equation, writing out the expected value explicitly in terms of "
                                },
                                {
                                    "bbox": [
                                        64,
                                        442,
                                        490,
                                        522
                                    ],
                                    "type": "inline_equation",
                                    "content": "p(s^{\\prime},r|s,a)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        442,
                                        490,
                                        522
                                    ],
                                    "type": "text",
                                    "content": " defined by (3.2), such that no expected value notation appears in the equation."
                                }
                            ]
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        64,
                        541,
                        471,
                        559
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                541,
                                471,
                                559
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        541,
                                        471,
                                        559
                                    ],
                                    "type": "text",
                                    "content": "3.6 Optimal Policies and Optimal Value Functions"
                                }
                            ]
                        }
                    ],
                    "index": 6,
                    "level": 1
                },
                {
                    "bbox": [
                        64,
                        570,
                        490,
                        691
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                570,
                                490,
                                691
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        691
                                    ],
                                    "type": "text",
                                    "content": "Solving a reinforcement learning task means, roughly, finding a policy that achieves a lot of reward over the long run. For finite MDPs, we can precisely define an optimal policy in the following way. Value functions define a partial ordering over policies. A policy "
                                },
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        691
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi"
                                },
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        691
                                    ],
                                    "type": "text",
                                    "content": " is defined to be better than or equal to a policy "
                                },
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        691
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi^{\\prime}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        691
                                    ],
                                    "type": "text",
                                    "content": " if its expected return is greater than or equal to that of "
                                },
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        691
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi^{\\prime}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        691
                                    ],
                                    "type": "text",
                                    "content": " for all states. In other words, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        691
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi \\geq \\pi^{\\prime}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        691
                                    ],
                                    "type": "text",
                                    "content": " if and only if "
                                },
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        691
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}(s)\\geq v_{\\pi^{\\prime}}(s)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        691
                                    ],
                                    "type": "text",
                                    "content": " for all "
                                },
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        691
                                    ],
                                    "type": "inline_equation",
                                    "content": "s\\in \\mathcal{S}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        691
                                    ],
                                    "type": "text",
                                    "content": " . There is always at least one policy that is better than or equal to all other policies. This is an optimal policy. Although there may be more than one, we denote all the optimal policies by "
                                },
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        691
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        691
                                    ],
                                    "type": "text",
                                    "content": " . They share the same state- value function, called the optimal state- value function, denoted "
                                },
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        691
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        570,
                                        490,
                                        691
                                    ],
                                    "type": "text",
                                    "content": " , and defined as"
                                }
                            ]
                        }
                    ],
                    "index": 7
                },
                {
                    "bbox": [
                        92,
                        699,
                        488,
                        718
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                92,
                                699,
                                488,
                                718
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        92,
                                        699,
                                        488,
                                        718
                                    ],
                                    "type": "interline_equation",
                                    "content": "v_{*}(s)\\doteq \\max_{\\pi}v_{\\pi}(s), \\tag{3.15}",
                                    "image_path": "baa752160867c8674b10eb5fa736517eb98bf86eb44397170c0afa04c76577a2.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 8
                },
                {
                    "bbox": [
                        63,
                        727,
                        125,
                        740
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                63,
                                727,
                                125,
                                740
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        63,
                                        727,
                                        125,
                                        740
                                    ],
                                    "type": "text",
                                    "content": "for all "
                                },
                                {
                                    "bbox": [
                                        63,
                                        727,
                                        125,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "s\\in \\mathcal{S}"
                                }
                            ]
                        }
                    ],
                    "index": 9
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 15
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        104,
                        140,
                        529,
                        167
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                140,
                                529,
                                167
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        140,
                                        529,
                                        167
                                    ],
                                    "type": "text",
                                    "content": "Optimal policies also share the same optimal action- value function, denoted "
                                },
                                {
                                    "bbox": [
                                        104,
                                        140,
                                        529,
                                        167
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        140,
                                        529,
                                        167
                                    ],
                                    "type": "text",
                                    "content": ", and defined as"
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        132,
                        177,
                        528,
                        196
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                132,
                                177,
                                528,
                                196
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        132,
                                        177,
                                        528,
                                        196
                                    ],
                                    "type": "interline_equation",
                                    "content": "q_{*}(s,a) \\doteq \\max_{\\pi} q_{\\pi}(s,a), \\tag{3.16}",
                                    "image_path": "d9e1bda8d33b5bfd356177fa4b670dda60b4bc5bf194323ba5c063d598618706.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        104,
                        205,
                        530,
                        246
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                205,
                                530,
                                246
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        205,
                                        530,
                                        246
                                    ],
                                    "type": "text",
                                    "content": "for all "
                                },
                                {
                                    "bbox": [
                                        104,
                                        205,
                                        530,
                                        246
                                    ],
                                    "type": "inline_equation",
                                    "content": "s \\in \\mathcal{S}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        205,
                                        530,
                                        246
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        104,
                                        205,
                                        530,
                                        246
                                    ],
                                    "type": "inline_equation",
                                    "content": "a \\in \\mathcal{A}(s)"
                                },
                                {
                                    "bbox": [
                                        104,
                                        205,
                                        530,
                                        246
                                    ],
                                    "type": "text",
                                    "content": ". For the state- action pair "
                                },
                                {
                                    "bbox": [
                                        104,
                                        205,
                                        530,
                                        246
                                    ],
                                    "type": "inline_equation",
                                    "content": "(s,a)"
                                },
                                {
                                    "bbox": [
                                        104,
                                        205,
                                        530,
                                        246
                                    ],
                                    "type": "text",
                                    "content": ", this function gives the expected return for taking action "
                                },
                                {
                                    "bbox": [
                                        104,
                                        205,
                                        530,
                                        246
                                    ],
                                    "type": "inline_equation",
                                    "content": "a"
                                },
                                {
                                    "bbox": [
                                        104,
                                        205,
                                        530,
                                        246
                                    ],
                                    "type": "text",
                                    "content": " in state "
                                },
                                {
                                    "bbox": [
                                        104,
                                        205,
                                        530,
                                        246
                                    ],
                                    "type": "inline_equation",
                                    "content": "s"
                                },
                                {
                                    "bbox": [
                                        104,
                                        205,
                                        530,
                                        246
                                    ],
                                    "type": "text",
                                    "content": " and thereafter following an optimal policy. Thus, we can write "
                                },
                                {
                                    "bbox": [
                                        104,
                                        205,
                                        530,
                                        246
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        205,
                                        530,
                                        246
                                    ],
                                    "type": "text",
                                    "content": " in terms of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        205,
                                        530,
                                        246
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        205,
                                        530,
                                        246
                                    ],
                                    "type": "text",
                                    "content": " as follows:"
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        132,
                        257,
                        528,
                        271
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                132,
                                257,
                                528,
                                271
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        132,
                                        257,
                                        528,
                                        271
                                    ],
                                    "type": "interline_equation",
                                    "content": "q_{*}(s,a) = \\mathbb{E}[R_{t + 1} + \\gamma v_{*}(S_{t + 1}) \\mid S_{t} = s, A_{t} = a]. \\tag{3.17}",
                                    "image_path": "b17f3ccbdafd8d8a0297350342331d9c3c3534ccda25b0a63cd495ab6823f4a3.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        104,
                        284,
                        530,
                        458
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                284,
                                530,
                                458
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        284,
                                        530,
                                        458
                                    ],
                                    "type": "text",
                                    "content": "Example 3.7: Optimal Value Functions for Golf The lower part of Figure 3.3 shows the contours of a possible optimal action- value function "
                                },
                                {
                                    "bbox": [
                                        104,
                                        284,
                                        530,
                                        458
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}(s, \\text{driver})"
                                },
                                {
                                    "bbox": [
                                        104,
                                        284,
                                        530,
                                        458
                                    ],
                                    "type": "text",
                                    "content": ". These are the values of each state if we first play a stroke with the driver and afterward select either the driver or the putter, whichever is better. The driver enables us to hit the ball farther, but with less accuracy. We can reach the hole in one shot using the driver only if we are already very close; thus the "
                                },
                                {
                                    "bbox": [
                                        104,
                                        284,
                                        530,
                                        458
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 1"
                                },
                                {
                                    "bbox": [
                                        104,
                                        284,
                                        530,
                                        458
                                    ],
                                    "type": "text",
                                    "content": " contour for "
                                },
                                {
                                    "bbox": [
                                        104,
                                        284,
                                        530,
                                        458
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}(s, \\text{driver})"
                                },
                                {
                                    "bbox": [
                                        104,
                                        284,
                                        530,
                                        458
                                    ],
                                    "type": "text",
                                    "content": " covers only a small portion of the green. If we have two strokes, however, then we can reach the hole from much farther away, as shown by the "
                                },
                                {
                                    "bbox": [
                                        104,
                                        284,
                                        530,
                                        458
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 2"
                                },
                                {
                                    "bbox": [
                                        104,
                                        284,
                                        530,
                                        458
                                    ],
                                    "type": "text",
                                    "content": " contour. In this case we don't have to drive all the way to within the small "
                                },
                                {
                                    "bbox": [
                                        104,
                                        284,
                                        530,
                                        458
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 1"
                                },
                                {
                                    "bbox": [
                                        104,
                                        284,
                                        530,
                                        458
                                    ],
                                    "type": "text",
                                    "content": " contour, but only to anywhere on the green; from there we can use the putter. The optimal action- value function gives the values after committing to a particular first action, in this case, to the driver, but afterward using whichever actions are best. The "
                                },
                                {
                                    "bbox": [
                                        104,
                                        284,
                                        530,
                                        458
                                    ],
                                    "type": "inline_equation",
                                    "content": "- 3"
                                },
                                {
                                    "bbox": [
                                        104,
                                        284,
                                        530,
                                        458
                                    ],
                                    "type": "text",
                                    "content": " contour is still farther out and includes the starting tee. From the tee, the best sequence of actions is two drives and one putt, sinking the ball in three strokes."
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        104,
                        459,
                        530,
                        552
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                459,
                                530,
                                552
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        459,
                                        530,
                                        552
                                    ],
                                    "type": "text",
                                    "content": "Because "
                                },
                                {
                                    "bbox": [
                                        104,
                                        459,
                                        530,
                                        552
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        459,
                                        530,
                                        552
                                    ],
                                    "type": "text",
                                    "content": " is the value function for a policy, it must satisfy the self- consistency condition given by the Bellman equation for state values (3.14). Because it is the optimal value function, however, "
                                },
                                {
                                    "bbox": [
                                        104,
                                        459,
                                        530,
                                        552
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        459,
                                        530,
                                        552
                                    ],
                                    "type": "text",
                                    "content": "'s consistency condition can be written in a special form without reference to any specific policy. This is the Bellman equation for "
                                },
                                {
                                    "bbox": [
                                        104,
                                        459,
                                        530,
                                        552
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        459,
                                        530,
                                        552
                                    ],
                                    "type": "text",
                                    "content": ", or the Bellman optimality equation. Intuitively, the Bellman optimality equation expresses the fact that the value of a state under an optimal policy must equal the expected return for the best action from that state:"
                                }
                            ]
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        130,
                        562,
                        528,
                        682
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                130,
                                562,
                                528,
                                682
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        130,
                                        562,
                                        528,
                                        682
                                    ],
                                    "type": "interline_equation",
                                    "content": "\\begin{array}{r l} & {v_{*}(s) = \\underset {a\\in \\mathcal{A}(s)}{\\max}q_{\\pi_{*}}(s,a)}\\\\ & {\\qquad = \\underset {a}{\\max}E_{\\pi_{*}}[G_{t}\\mid S_{t} = s,A_{t} = a]}\\\\ & {\\qquad = \\underset {a}{\\max}E_{\\pi_{*}}[R_{t + 1} + \\gamma G_{t + 1}\\mid S_{t} = s,A_{t} = a]}\\\\ & {\\qquad = \\underset {a}{\\max}E[R_{t + 1} + \\gamma v_{*}(S_{t + 1})\\mid S_{t} = s,A_{t} = a]}\\\\ & {\\qquad = \\underset {a}{\\max}\\sum_{r}p(s^{\\prime},r\\mid s,a)[r + \\gamma v_{*}(s^{\\prime})].} \\end{array} \\tag{by (3.9)",
                                    "image_path": "3abbbdfc5c4676265f2b66d0b196975635d2c549dcfe4e21338e723e447876b1.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 6
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 16
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        64,
                        140,
                        489,
                        168
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                140,
                                489,
                                168
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        140,
                                        489,
                                        168
                                    ],
                                    "type": "text",
                                    "content": "The last two equations are two forms of the Bellman optimality equation for "
                                },
                                {
                                    "bbox": [
                                        64,
                                        140,
                                        489,
                                        168
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        140,
                                        489,
                                        168
                                    ],
                                    "type": "text",
                                    "content": ". The Bellman optimality equation for "
                                },
                                {
                                    "bbox": [
                                        64,
                                        140,
                                        489,
                                        168
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        140,
                                        489,
                                        168
                                    ],
                                    "type": "text",
                                    "content": " is"
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        91,
                        174,
                        489,
                        232
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                91,
                                174,
                                489,
                                232
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        91,
                                        174,
                                        489,
                                        232
                                    ],
                                    "type": "interline_equation",
                                    "content": "\\begin{array}{rcl}{q_{*}(s,a)} & = & {\\mathbb{E}\\Big[R_{t + 1} + \\gamma \\max_{a^{\\prime}}q_{*}(S_{t + 1},a^{\\prime})\\Big|S_{t} = s,A_{t} = a\\Big]}\\\\ {} & = & {\\sum_{s^{\\prime},r}p(s^{\\prime},r|s,a)\\Big[r + \\gamma \\max_{a^{\\prime}}q_{*}(s^{\\prime},a^{\\prime})\\Big].} \\end{array} \\tag{3.20}",
                                    "image_path": "d4e34576da7a69e955c9a0289dd27090b2d8fcba98f5dd615df72b942162ad8e.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        64,
                        239,
                        490,
                        333
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                239,
                                490,
                                333
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        239,
                                        490,
                                        333
                                    ],
                                    "type": "text",
                                    "content": "The backup diagrams in the figure below show graphically the spans of future states and actions considered in the Bellman optimality equations for "
                                },
                                {
                                    "bbox": [
                                        64,
                                        239,
                                        490,
                                        333
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        239,
                                        490,
                                        333
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        239,
                                        490,
                                        333
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        239,
                                        490,
                                        333
                                    ],
                                    "type": "text",
                                    "content": ". These are the same as the backup diagrams for "
                                },
                                {
                                    "bbox": [
                                        64,
                                        239,
                                        490,
                                        333
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        239,
                                        490,
                                        333
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        239,
                                        490,
                                        333
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        239,
                                        490,
                                        333
                                    ],
                                    "type": "text",
                                    "content": " presented earlier except that arcs have been added at the agent's choice points to represent that the maximum over that choice is taken rather than the expected value given some policy. The backup diagram on the left graphically represents the Bellman optimality equation (3.19) and the backup diagram on the right graphically represents (3.20)."
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "type": "image",
                    "bbox": [
                        148,
                        346,
                        406,
                        425
                    ],
                    "blocks": [
                        {
                            "bbox": [
                                148,
                                346,
                                406,
                                425
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        148,
                                        346,
                                        406,
                                        425
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                148,
                                                346,
                                                406,
                                                425
                                            ],
                                            "type": "image",
                                            "image_path": "adee9e6eb1277a118dbd9ca5a1fe0aae081fd477638b9d5addec723553399f24.jpg"
                                        }
                                    ]
                                }
                            ],
                            "index": 3,
                            "type": "image_body"
                        },
                        {
                            "bbox": [
                                175,
                                434,
                                377,
                                447
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        175,
                                        434,
                                        377,
                                        447
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                175,
                                                434,
                                                377,
                                                447
                                            ],
                                            "type": "text",
                                            "content": "Figure 3.4: Backup diagrams for "
                                        },
                                        {
                                            "bbox": [
                                                175,
                                                434,
                                                377,
                                                447
                                            ],
                                            "type": "inline_equation",
                                            "content": "v_{*}"
                                        },
                                        {
                                            "bbox": [
                                                175,
                                                434,
                                                377,
                                                447
                                            ],
                                            "type": "text",
                                            "content": " and "
                                        },
                                        {
                                            "bbox": [
                                                175,
                                                434,
                                                377,
                                                447
                                            ],
                                            "type": "inline_equation",
                                            "content": "q_{*}"
                                        }
                                    ]
                                }
                            ],
                            "index": 4,
                            "type": "image_caption"
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        64,
                        460,
                        490,
                        540
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                460,
                                490,
                                540
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        460,
                                        490,
                                        540
                                    ],
                                    "type": "text",
                                    "content": "For finite MDPs, the Bellman optimality equation for "
                                },
                                {
                                    "bbox": [
                                        64,
                                        460,
                                        490,
                                        540
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        460,
                                        490,
                                        540
                                    ],
                                    "type": "text",
                                    "content": " (3.19) has a unique solution. The Bellman optimality equation is actually a system of equations, one for each state, so if there are "
                                },
                                {
                                    "bbox": [
                                        64,
                                        460,
                                        490,
                                        540
                                    ],
                                    "type": "inline_equation",
                                    "content": "n"
                                },
                                {
                                    "bbox": [
                                        64,
                                        460,
                                        490,
                                        540
                                    ],
                                    "type": "text",
                                    "content": " states, then there are "
                                },
                                {
                                    "bbox": [
                                        64,
                                        460,
                                        490,
                                        540
                                    ],
                                    "type": "inline_equation",
                                    "content": "n"
                                },
                                {
                                    "bbox": [
                                        64,
                                        460,
                                        490,
                                        540
                                    ],
                                    "type": "text",
                                    "content": " equations in "
                                },
                                {
                                    "bbox": [
                                        64,
                                        460,
                                        490,
                                        540
                                    ],
                                    "type": "inline_equation",
                                    "content": "n"
                                },
                                {
                                    "bbox": [
                                        64,
                                        460,
                                        490,
                                        540
                                    ],
                                    "type": "text",
                                    "content": " unknowns. If the dynamics "
                                },
                                {
                                    "bbox": [
                                        64,
                                        460,
                                        490,
                                        540
                                    ],
                                    "type": "inline_equation",
                                    "content": "p"
                                },
                                {
                                    "bbox": [
                                        64,
                                        460,
                                        490,
                                        540
                                    ],
                                    "type": "text",
                                    "content": " of the environment are known, then in principle one can solve this system of equations for "
                                },
                                {
                                    "bbox": [
                                        64,
                                        460,
                                        490,
                                        540
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        460,
                                        490,
                                        540
                                    ],
                                    "type": "text",
                                    "content": " using any one of a variety of methods for solving systems of nonlinear equations. One can solve a related set of equations for "
                                },
                                {
                                    "bbox": [
                                        64,
                                        460,
                                        490,
                                        540
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        460,
                                        490,
                                        540
                                    ],
                                    "type": "text",
                                    "content": "."
                                }
                            ]
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        64,
                        541,
                        490,
                        740
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                541,
                                490,
                                740
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        541,
                                        490,
                                        740
                                    ],
                                    "type": "text",
                                    "content": "Once one has "
                                },
                                {
                                    "bbox": [
                                        64,
                                        541,
                                        490,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        541,
                                        490,
                                        740
                                    ],
                                    "type": "text",
                                    "content": ", it is relatively easy to determine an optimal policy. For each state "
                                },
                                {
                                    "bbox": [
                                        64,
                                        541,
                                        490,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "s"
                                },
                                {
                                    "bbox": [
                                        64,
                                        541,
                                        490,
                                        740
                                    ],
                                    "type": "text",
                                    "content": ", there will be one or more actions at which the maximum is obtained in the Bellman optimality equation. Any policy that assigns nonzero probability only to these actions is an optimal policy. You can think of this as a one- step search. If you have the optimal value function, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        541,
                                        490,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        541,
                                        490,
                                        740
                                    ],
                                    "type": "text",
                                    "content": ", then the actions that appear best after a one- step search will be optimal actions. Another way of saying this is that any policy that is greedy with respect to the optimal evaluation function "
                                },
                                {
                                    "bbox": [
                                        64,
                                        541,
                                        490,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        541,
                                        490,
                                        740
                                    ],
                                    "type": "text",
                                    "content": " is an optimal policy. The term greedy is used in computer science to describe any search or decision procedure that selects alternatives based only on local or immediate considerations, without considering the possibility that such a selection may prevent future access to even better alternatives. Consequently, it describes policies that select actions based only on their short- term consequences. The beauty of "
                                },
                                {
                                    "bbox": [
                                        64,
                                        541,
                                        490,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        541,
                                        490,
                                        740
                                    ],
                                    "type": "text",
                                    "content": " is that if one uses it to evaluate the short- term consequences of actionsâ€”specifically, the one- step consequencesâ€”then a greedy policy is actually optimal in the long- term sense in which we are interested because "
                                },
                                {
                                    "bbox": [
                                        64,
                                        541,
                                        490,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        541,
                                        490,
                                        740
                                    ],
                                    "type": "text",
                                    "content": " already takes into account the reward consequences of all possible future behavior. By means of "
                                },
                                {
                                    "bbox": [
                                        64,
                                        541,
                                        490,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        541,
                                        490,
                                        740
                                    ],
                                    "type": "text",
                                    "content": ", the optimal expected long- term return is"
                                }
                            ]
                        }
                    ],
                    "index": 6
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 17
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        104,
                        140,
                        530,
                        167
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                140,
                                530,
                                167
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        140,
                                        530,
                                        167
                                    ],
                                    "type": "text",
                                    "content": "turned into a quantity that is locally and immediately available for each state. Hence, a one- step- ahead search yields the long- term optimal actions."
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        104,
                        169,
                        530,
                        287
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                169,
                                530,
                                287
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        169,
                                        530,
                                        287
                                    ],
                                    "type": "text",
                                    "content": "Having "
                                },
                                {
                                    "bbox": [
                                        104,
                                        169,
                                        530,
                                        287
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        169,
                                        530,
                                        287
                                    ],
                                    "type": "text",
                                    "content": " makes choosing optimal actions even easier. With "
                                },
                                {
                                    "bbox": [
                                        104,
                                        169,
                                        530,
                                        287
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        169,
                                        530,
                                        287
                                    ],
                                    "type": "text",
                                    "content": ", the agent does not even have to do a one- step- ahead search: for any state "
                                },
                                {
                                    "bbox": [
                                        104,
                                        169,
                                        530,
                                        287
                                    ],
                                    "type": "inline_equation",
                                    "content": "s"
                                },
                                {
                                    "bbox": [
                                        104,
                                        169,
                                        530,
                                        287
                                    ],
                                    "type": "text",
                                    "content": ", it can simply find any action that maximizes "
                                },
                                {
                                    "bbox": [
                                        104,
                                        169,
                                        530,
                                        287
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}(s, a)"
                                },
                                {
                                    "bbox": [
                                        104,
                                        169,
                                        530,
                                        287
                                    ],
                                    "type": "text",
                                    "content": ". The action- value function effectively caches the results of all one- step- ahead searches. It provides the optimal expected long- term return as a value that is locally and immediately available for each state- action pair. Hence, at the cost of representing a function of state- action pairs, instead of just of states, the optimal action- value function allows optimal actions to be selected without having to know anything about possible successor states and their values, that is, without having to know anything about the environment's dynamics."
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        104,
                        293,
                        530,
                        373
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                293,
                                530,
                                373
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        293,
                                        530,
                                        373
                                    ],
                                    "type": "text",
                                    "content": "Example 3.8: Solving the Gridworld Suppose we solve the Bellman equation for "
                                },
                                {
                                    "bbox": [
                                        104,
                                        293,
                                        530,
                                        373
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        293,
                                        530,
                                        373
                                    ],
                                    "type": "text",
                                    "content": " for the simple grid task introduced in Example 3.5 and shown again in Figure 3.5 (left). Recall that state A is followed by a reward of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        293,
                                        530,
                                        373
                                    ],
                                    "type": "inline_equation",
                                    "content": "+10"
                                },
                                {
                                    "bbox": [
                                        104,
                                        293,
                                        530,
                                        373
                                    ],
                                    "type": "text",
                                    "content": " and transition to state "
                                },
                                {
                                    "bbox": [
                                        104,
                                        293,
                                        530,
                                        373
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\mathsf{A}^{\\prime}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        293,
                                        530,
                                        373
                                    ],
                                    "type": "text",
                                    "content": ", while state B is followed by a reward of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        293,
                                        530,
                                        373
                                    ],
                                    "type": "inline_equation",
                                    "content": "+5"
                                },
                                {
                                    "bbox": [
                                        104,
                                        293,
                                        530,
                                        373
                                    ],
                                    "type": "text",
                                    "content": " and transition to state "
                                },
                                {
                                    "bbox": [
                                        104,
                                        293,
                                        530,
                                        373
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\mathsf{B}^{\\prime}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        293,
                                        530,
                                        373
                                    ],
                                    "type": "text",
                                    "content": ". Figure 3.5 (middle) shows the optimal value function, and Figure 3.5 (right) shows the corresponding optimal policies. Where there are multiple arrows in a cell, all of the corresponding actions are optimal."
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "type": "image",
                    "bbox": [
                        161,
                        404,
                        486,
                        518
                    ],
                    "blocks": [
                        {
                            "bbox": [
                                161,
                                404,
                                486,
                                518
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        161,
                                        404,
                                        486,
                                        518
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                161,
                                                404,
                                                486,
                                                518
                                            ],
                                            "type": "image",
                                            "image_path": "7ba4f7e637d7dfec437cf74a5bf32ad6948008ac68aef40b23084a1fa89a39a7.jpg"
                                        }
                                    ]
                                }
                            ],
                            "index": 3,
                            "type": "image_body"
                        },
                        {
                            "bbox": [
                                186,
                                525,
                                446,
                                538
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        186,
                                        525,
                                        446,
                                        538
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                186,
                                                525,
                                                446,
                                                538
                                            ],
                                            "type": "text",
                                            "content": "Figure 3.5: Optimal solutions to the gridworld example."
                                        }
                                    ]
                                }
                            ],
                            "index": 4,
                            "type": "image_caption"
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        104,
                        559,
                        530,
                        640
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                559,
                                530,
                                640
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        559,
                                        530,
                                        640
                                    ],
                                    "type": "text",
                                    "content": "Example 3.9: Bellman Optimality Equations for the Recycling Robot Using (3.19), we can explicitly give the Bellman optimality equation for the recycling robot example. To make things more compact, we abbreviate the states high and low, and the actions search, wait, and recharge respectively by h, l, s, w, and re. Because there are only two states, the Bellman optimality equation consists of two equations. The equation for "
                                },
                                {
                                    "bbox": [
                                        104,
                                        559,
                                        530,
                                        640
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}(\\mathbf{h})"
                                },
                                {
                                    "bbox": [
                                        104,
                                        559,
                                        530,
                                        640
                                    ],
                                    "type": "text",
                                    "content": " can be written as follows:"
                                }
                            ]
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        130,
                        652,
                        523,
                        746
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                130,
                                652,
                                523,
                                746
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        130,
                                        652,
                                        523,
                                        746
                                    ],
                                    "type": "interline_equation",
                                    "content": "\\begin{array}{r l r}{v_{*}(\\mathbf{h})} & = & {\\max \\left\\{ \\begin{array}{l}{p(\\mathbf{h}|\\mathbf{h},\\mathbf{s})[r(\\mathbf{h},\\mathbf{s},\\mathbf{h}) + \\gamma v_{*}(\\mathbf{h})] + p(\\mathbf{l}|\\mathbf{h},\\mathbf{s})[r(\\mathbf{h},\\mathbf{s},\\mathbf{l}) + \\gamma v_{*}(\\mathbf{l})],}\\\\ {p(\\mathbf{h}|\\mathbf{h},\\mathbf{w})[r(\\mathbf{h},\\mathbf{w},\\mathbf{h}) + \\gamma v_{*}(\\mathbf{h})] + p(\\mathbf{l}|\\mathbf{h},\\mathbf{w})[r(\\mathbf{h},\\mathbf{w},\\mathbf{l}) + \\gamma v_{*}(\\mathbf{l})]} \\end{array} \\right\\}}\\\\ & = & {\\max \\left\\{ \\begin{array}{l}{\\alpha [r_{\\mathbf{s}} + \\gamma v_{*}(\\mathbf{h})] + (1 - \\alpha)[r_{\\mathbf{s}} + \\gamma v_{*}(\\mathbf{l})],}\\\\ {1[r_{\\mathbf{w}} + \\gamma v_{*}(\\mathbf{h})] + 0[r_{\\mathbf{w}} + \\gamma v_{*}(\\mathbf{l})]} \\end{array} \\right\\}}\\\\ & = & {\\max \\left\\{ \\begin{array}{l}{r_{\\mathbf{s}} + \\gamma [\\alpha v_{*}(\\mathbf{h}) + (1 - \\alpha)v_{*}(\\mathbf{l})],}\\\\ {r_{\\mathbf{w}} + \\gamma v_{*}(\\mathbf{h})} \\end{array} \\right\\} .} \\end{array}",
                                    "image_path": "c4169a0e801907269a192a87e66c6926ef3a93d677561c6c5ec3ba24abf9cd37.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 6
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 18
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        64,
                        140,
                        351,
                        154
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                140,
                                351,
                                154
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        140,
                                        351,
                                        154
                                    ],
                                    "type": "text",
                                    "content": "Following the same procedure for "
                                },
                                {
                                    "bbox": [
                                        64,
                                        140,
                                        351,
                                        154
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}(1)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        140,
                                        351,
                                        154
                                    ],
                                    "type": "text",
                                    "content": " yields the equation"
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        92,
                        166,
                        395,
                        211
                    ],
                    "type": "interline_equation",
                    "lines": [
                        {
                            "bbox": [
                                92,
                                166,
                                395,
                                211
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        92,
                                        166,
                                        395,
                                        211
                                    ],
                                    "type": "interline_equation",
                                    "content": "v_{*}(1) = \\max \\left\\{ \\begin{array}{l l}{\\beta r_{\\mathbf{s}} - 3(1 - \\beta) + \\gamma [(1 - \\beta)v_{*}(\\mathbf{h}) + \\beta v_{*}(1)],}\\\\ {r_{\\mathbf{w}} + \\gamma v_{*}(1),}\\\\ {\\gamma v_{*}(\\mathbf{h})} \\end{array} \\right\\} .",
                                    "image_path": "154ffbc47a250862ac62f0060ce278b47d2eb1b590ea30399558977c21406c07.jpg"
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        64,
                        219,
                        489,
                        261
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                219,
                                489,
                                261
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        219,
                                        489,
                                        261
                                    ],
                                    "type": "text",
                                    "content": "For any choice of "
                                },
                                {
                                    "bbox": [
                                        64,
                                        219,
                                        489,
                                        261
                                    ],
                                    "type": "inline_equation",
                                    "content": "r_{\\mathrm{s}}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        219,
                                        489,
                                        261
                                    ],
                                    "type": "inline_equation",
                                    "content": "r_{\\mathrm{w}}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        219,
                                        489,
                                        261
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\alpha"
                                },
                                {
                                    "bbox": [
                                        64,
                                        219,
                                        489,
                                        261
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\beta"
                                },
                                {
                                    "bbox": [
                                        64,
                                        219,
                                        489,
                                        261
                                    ],
                                    "type": "text",
                                    "content": " , and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        219,
                                        489,
                                        261
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\gamma"
                                },
                                {
                                    "bbox": [
                                        64,
                                        219,
                                        489,
                                        261
                                    ],
                                    "type": "text",
                                    "content": " , with "
                                },
                                {
                                    "bbox": [
                                        64,
                                        219,
                                        489,
                                        261
                                    ],
                                    "type": "inline_equation",
                                    "content": "0\\leq \\gamma < 1"
                                },
                                {
                                    "bbox": [
                                        64,
                                        219,
                                        489,
                                        261
                                    ],
                                    "type": "inline_equation",
                                    "content": "0\\leq \\alpha ,\\beta \\leq 1"
                                },
                                {
                                    "bbox": [
                                        64,
                                        219,
                                        489,
                                        261
                                    ],
                                    "type": "text",
                                    "content": " , there is exactly one pair of numbers, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        219,
                                        489,
                                        261
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}(\\mathbf{h})"
                                },
                                {
                                    "bbox": [
                                        64,
                                        219,
                                        489,
                                        261
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        219,
                                        489,
                                        261
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}(1)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        219,
                                        489,
                                        261
                                    ],
                                    "type": "text",
                                    "content": " , that simultaneously satisfy these two nonlinear equations."
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        64,
                        261,
                        490,
                        447
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                261,
                                490,
                                447
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        261,
                                        490,
                                        447
                                    ],
                                    "type": "text",
                                    "content": "Explicitly solving the Bellman optimality equation provides one route to finding an optimal policy, and thus to solving the reinforcement learning problem. However, this solution is rarely directly useful. It is akin to an exhaustive search, looking ahead at all possibilities, computing their probabilities of occurrence and their desirabilities in terms of expected rewards. This solution relies on at least three assumptions that are rarely true in practice: (1) the dynamics of the environment are accurately known; (2) computational resources are sufficient to complete the calculation; and (3) the states have the Markov property. For the kinds of tasks in which we are interested, one is generally not able to implement this solution exactly because various combinations of these assumptions are violated. For example, although the first and third assumptions present no problems for the game of backgammon, the second is a major impediment. Because the game has about "
                                },
                                {
                                    "bbox": [
                                        64,
                                        261,
                                        490,
                                        447
                                    ],
                                    "type": "inline_equation",
                                    "content": "10^{20}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        261,
                                        490,
                                        447
                                    ],
                                    "type": "text",
                                    "content": " states, it would take thousands of years on today's fastest computers to solve the Bellman equation for "
                                },
                                {
                                    "bbox": [
                                        64,
                                        261,
                                        490,
                                        447
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        261,
                                        490,
                                        447
                                    ],
                                    "type": "text",
                                    "content": ", and the same is true for finding "
                                },
                                {
                                    "bbox": [
                                        64,
                                        261,
                                        490,
                                        447
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        261,
                                        490,
                                        447
                                    ],
                                    "type": "text",
                                    "content": ". In reinforcement learning one typically has to settle for approximate solutions."
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        64,
                        448,
                        490,
                        580
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                448,
                                490,
                                580
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        448,
                                        490,
                                        580
                                    ],
                                    "type": "text",
                                    "content": "Many different decision- making methods can be viewed as ways of approximately solving the Bellman optimality equation. For example, heuristic search methods can be viewed as expanding the right- hand side of (3.19) several times, up to some depth, forming a \"tree\" of possibilities, and then using a heuristic evaluation function to approximate "
                                },
                                {
                                    "bbox": [
                                        64,
                                        448,
                                        490,
                                        580
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        448,
                                        490,
                                        580
                                    ],
                                    "type": "text",
                                    "content": " at the \"leaf\" nodes. (Heuristic search methods such as "
                                },
                                {
                                    "bbox": [
                                        64,
                                        448,
                                        490,
                                        580
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\mathrm{A}^{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        448,
                                        490,
                                        580
                                    ],
                                    "type": "text",
                                    "content": " are almost always based on the episodic case.) The methods of dynamic programming can be related even more closely to the Bellman optimality equation. Many reinforcement learning methods can be clearly understood as approximately solving the Bellman optimality equation, using actual experienced transitions in place of knowledge of the expected transitions. We consider a variety of such methods in the following chapters."
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        64,
                        595,
                        489,
                        609
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                595,
                                489,
                                609
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        595,
                                        489,
                                        609
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.20 Draw or describe the optimal state- value function for the golf example. "
                                },
                                {
                                    "bbox": [
                                        64,
                                        595,
                                        489,
                                        609
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\square"
                                }
                            ]
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        64,
                        614,
                        489,
                        642
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                614,
                                489,
                                642
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        614,
                                        489,
                                        642
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.21 Draw or describe the contours of the optimal action- value function for putting, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        614,
                                        489,
                                        642
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}(s, \\text{putter})"
                                },
                                {
                                    "bbox": [
                                        64,
                                        614,
                                        489,
                                        642
                                    ],
                                    "type": "text",
                                    "content": ", for the golf example. "
                                },
                                {
                                    "bbox": [
                                        64,
                                        614,
                                        489,
                                        642
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\square"
                                }
                            ]
                        }
                    ],
                    "index": 6
                },
                {
                    "bbox": [
                        64,
                        647,
                        348,
                        740
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                647,
                                348,
                                740
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        647,
                                        348,
                                        740
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.22 Consider the continuing MDP shown to the right. The only decision to be made is that in the top state, where two actions are available, left and right. The numbers show the rewards that are received deterministically after each action. There are exactly two deterministic policies, "
                                },
                                {
                                    "bbox": [
                                        64,
                                        647,
                                        348,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi_{\\text{left}}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        647,
                                        348,
                                        740
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        647,
                                        348,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi_{\\text{right}}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        647,
                                        348,
                                        740
                                    ],
                                    "type": "text",
                                    "content": ". What policy is optimal if "
                                },
                                {
                                    "bbox": [
                                        64,
                                        647,
                                        348,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\gamma = 0"
                                },
                                {
                                    "bbox": [
                                        64,
                                        647,
                                        348,
                                        740
                                    ],
                                    "type": "text",
                                    "content": "? If "
                                },
                                {
                                    "bbox": [
                                        64,
                                        647,
                                        348,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\gamma = 0.9"
                                },
                                {
                                    "bbox": [
                                        64,
                                        647,
                                        348,
                                        740
                                    ],
                                    "type": "text",
                                    "content": "? If "
                                },
                                {
                                    "bbox": [
                                        64,
                                        647,
                                        348,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\gamma = 0.5"
                                },
                                {
                                    "bbox": [
                                        64,
                                        647,
                                        348,
                                        740
                                    ],
                                    "type": "text",
                                    "content": "? "
                                },
                                {
                                    "bbox": [
                                        64,
                                        647,
                                        348,
                                        740
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\square"
                                }
                            ]
                        }
                    ],
                    "index": 7
                },
                {
                    "type": "image",
                    "bbox": [
                        364,
                        651,
                        490,
                        737
                    ],
                    "blocks": [
                        {
                            "bbox": [
                                364,
                                651,
                                490,
                                737
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        364,
                                        651,
                                        490,
                                        737
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                364,
                                                651,
                                                490,
                                                737
                                            ],
                                            "type": "image",
                                            "image_path": "9abf580921e42f1daf06a599e433995931e5bd428c167aded6e4f6156a19e83f.jpg"
                                        }
                                    ]
                                }
                            ],
                            "index": 8,
                            "type": "image_body"
                        }
                    ],
                    "index": 8
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 19
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        104,
                        140,
                        452,
                        154
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                140,
                                452,
                                154
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        140,
                                        452,
                                        154
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.23 Give the Bellman equation for "
                                },
                                {
                                    "bbox": [
                                        104,
                                        140,
                                        452,
                                        154
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        140,
                                        452,
                                        154
                                    ],
                                    "type": "text",
                                    "content": " for the recycling robot. "
                                },
                                {
                                    "bbox": [
                                        104,
                                        140,
                                        452,
                                        154
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\square"
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        104,
                        158,
                        529,
                        198
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                158,
                                529,
                                198
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        158,
                                        529,
                                        198
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.24 Figure 3.5 gives the optimal value of the best state of the gridworld as 24.4, to one decimal place. Use your knowledge of the optimal policy and (3.8) to express this value symbolically, and then to compute it to three decimal places. "
                                },
                                {
                                    "bbox": [
                                        104,
                                        158,
                                        529,
                                        198
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\square"
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        104,
                        202,
                        362,
                        216
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                202,
                                362,
                                216
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        202,
                                        362,
                                        216
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.25 Give an equation for "
                                },
                                {
                                    "bbox": [
                                        104,
                                        202,
                                        362,
                                        216
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        202,
                                        362,
                                        216
                                    ],
                                    "type": "text",
                                    "content": " in terms of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        202,
                                        362,
                                        216
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        202,
                                        362,
                                        216
                                    ],
                                    "type": "text",
                                    "content": ". "
                                },
                                {
                                    "bbox": [
                                        104,
                                        202,
                                        362,
                                        216
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\square"
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        104,
                        221,
                        485,
                        234
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                221,
                                485,
                                234
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        221,
                                        485,
                                        234
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.26 Give an equation for "
                                },
                                {
                                    "bbox": [
                                        104,
                                        221,
                                        485,
                                        234
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        221,
                                        485,
                                        234
                                    ],
                                    "type": "text",
                                    "content": " in terms of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        221,
                                        485,
                                        234
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        221,
                                        485,
                                        234
                                    ],
                                    "type": "text",
                                    "content": " and the four- argument "
                                },
                                {
                                    "bbox": [
                                        104,
                                        221,
                                        485,
                                        234
                                    ],
                                    "type": "inline_equation",
                                    "content": "p"
                                },
                                {
                                    "bbox": [
                                        104,
                                        221,
                                        485,
                                        234
                                    ],
                                    "type": "text",
                                    "content": ". "
                                },
                                {
                                    "bbox": [
                                        104,
                                        221,
                                        485,
                                        234
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\square"
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        104,
                        239,
                        364,
                        252
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                239,
                                364,
                                252
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        239,
                                        364,
                                        252
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.27 Give an equation for "
                                },
                                {
                                    "bbox": [
                                        104,
                                        239,
                                        364,
                                        252
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        239,
                                        364,
                                        252
                                    ],
                                    "type": "text",
                                    "content": " in terms of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        239,
                                        364,
                                        252
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        239,
                                        364,
                                        252
                                    ],
                                    "type": "text",
                                    "content": ". "
                                },
                                {
                                    "bbox": [
                                        104,
                                        239,
                                        364,
                                        252
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\square"
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        104,
                        257,
                        486,
                        270
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                257,
                                486,
                                270
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        257,
                                        486,
                                        270
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.28 Give an equation for "
                                },
                                {
                                    "bbox": [
                                        104,
                                        257,
                                        486,
                                        270
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\pi_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        257,
                                        486,
                                        270
                                    ],
                                    "type": "text",
                                    "content": " in terms of "
                                },
                                {
                                    "bbox": [
                                        104,
                                        257,
                                        486,
                                        270
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        257,
                                        486,
                                        270
                                    ],
                                    "type": "text",
                                    "content": " and the four- argument "
                                },
                                {
                                    "bbox": [
                                        104,
                                        257,
                                        486,
                                        270
                                    ],
                                    "type": "inline_equation",
                                    "content": "p"
                                },
                                {
                                    "bbox": [
                                        104,
                                        257,
                                        486,
                                        270
                                    ],
                                    "type": "text",
                                    "content": ". "
                                },
                                {
                                    "bbox": [
                                        104,
                                        257,
                                        486,
                                        270
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\square"
                                }
                            ]
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        104,
                        274,
                        529,
                        314
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                274,
                                529,
                                314
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        274,
                                        529,
                                        314
                                    ],
                                    "type": "text",
                                    "content": "Exercise 3.29 Rewrite the four Bellman equations for the four value functions "
                                },
                                {
                                    "bbox": [
                                        104,
                                        274,
                                        529,
                                        314
                                    ],
                                    "type": "inline_equation",
                                    "content": "(v_{\\pi}, v_{*}, q_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        274,
                                        529,
                                        314
                                    ],
                                    "type": "text",
                                    "content": ", and "
                                },
                                {
                                    "bbox": [
                                        104,
                                        274,
                                        529,
                                        314
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}"
                                },
                                {
                                    "bbox": [
                                        104,
                                        274,
                                        529,
                                        314
                                    ],
                                    "type": "text",
                                    "content": ") in terms of the three argument function "
                                },
                                {
                                    "bbox": [
                                        104,
                                        274,
                                        529,
                                        314
                                    ],
                                    "type": "inline_equation",
                                    "content": "p"
                                },
                                {
                                    "bbox": [
                                        104,
                                        274,
                                        529,
                                        314
                                    ],
                                    "type": "text",
                                    "content": " (3.4) and the two- argument function "
                                },
                                {
                                    "bbox": [
                                        104,
                                        274,
                                        529,
                                        314
                                    ],
                                    "type": "inline_equation",
                                    "content": "r"
                                },
                                {
                                    "bbox": [
                                        104,
                                        274,
                                        529,
                                        314
                                    ],
                                    "type": "text",
                                    "content": " (3.5). "
                                },
                                {
                                    "bbox": [
                                        104,
                                        274,
                                        529,
                                        314
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\square"
                                }
                            ]
                        }
                    ],
                    "index": 6
                },
                {
                    "bbox": [
                        104,
                        350,
                        390,
                        368
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                350,
                                390,
                                368
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        350,
                                        390,
                                        368
                                    ],
                                    "type": "text",
                                    "content": "3.7 Optimality and Approximation"
                                }
                            ]
                        }
                    ],
                    "index": 7,
                    "level": 1
                },
                {
                    "bbox": [
                        104,
                        378,
                        529,
                        552
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                378,
                                529,
                                552
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        378,
                                        529,
                                        552
                                    ],
                                    "type": "text",
                                    "content": "We have defined optimal value functions and optimal policies. Clearly, an agent that learns an optimal policy has done very well, but in practice this rarely happens. For the kinds of tasks in which we are interested, optimal policies can be generated only with extreme computational cost. A well- defined notion of optimality organizes the approach to learning we describe in this book and provides a way to understand the theoretical properties of various learning algorithms, but it is an ideal that agents can only approximate. As we discussed above, even if we have a complete and accurate model of the environment's dynamics, it is usually not possible to simply compute an optimal policy by solving the Bellman optimality equation. For example, board games such as chess are a tiny fraction of human experience, yet large, custom- designed computers still cannot compute the optimal moves. A critical aspect of the problem facing the agent is always the computational power available to it, in particular, the amount of computation it can perform in a single time step."
                                }
                            ]
                        }
                    ],
                    "index": 8
                },
                {
                    "bbox": [
                        104,
                        554,
                        529,
                        659
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                554,
                                529,
                                659
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        554,
                                        529,
                                        659
                                    ],
                                    "type": "text",
                                    "content": "The memory available is also an important constraint. A large amount of memory is often required to build up approximations of value functions, policies, and models. In tasks with small, finite state sets, it is possible to form these approximations using arrays or tables with one entry for each state (or state- action pair). This we call the tabular case, and the corresponding methods we call tabular methods. In many cases of practical interest, however, there are far more states than could possibly be entries in a table. In these cases the functions must be approximated, using some sort of more compact parameterized function representation."
                                }
                            ]
                        }
                    ],
                    "index": 9
                },
                {
                    "bbox": [
                        104,
                        660,
                        529,
                        740
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                660,
                                529,
                                740
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        660,
                                        529,
                                        740
                                    ],
                                    "type": "text",
                                    "content": "Our framing of the reinforcement learning problem forces us to settle for approximations. However, it also presents us with some unique opportunities for achieving useful approximations. For example, in approximating optimal behavior, there may be many states that the agent faces with such a low probability that selecting suboptimal actions for them has little impact on the amount of reward the agent receives. Tesauro's backgammon player, for example, plays with exceptional skill even though it might make"
                                }
                            ]
                        }
                    ],
                    "index": 10
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 20
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        64,
                        141,
                        489,
                        234
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                141,
                                489,
                                234
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        141,
                                        489,
                                        234
                                    ],
                                    "type": "text",
                                    "content": "very bad decisions on board configurations that never occur in games against experts. In fact, it is possible that TD- Gammon makes bad decisions for a large fraction of the game's state set. The online nature of reinforcement learning makes it possible to approximate optimal policies in ways that put more effort into learning to make good decisions for frequently encountered states, at the expense of less effort for infrequently encountered states. This is one key property that distinguishes reinforcement learning from other approaches to approximately solving MDPs."
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        64,
                        256,
                        181,
                        274
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                256,
                                181,
                                274
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        256,
                                        181,
                                        274
                                    ],
                                    "type": "text",
                                    "content": "3.8 Summary"
                                }
                            ]
                        }
                    ],
                    "index": 1,
                    "level": 1
                },
                {
                    "bbox": [
                        64,
                        286,
                        489,
                        418
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                286,
                                489,
                                418
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        286,
                                        489,
                                        418
                                    ],
                                    "type": "text",
                                    "content": "Let us summarize the elements of the reinforcement learning problem that we have presented in this chapter. Reinforcement learning is about learning from interaction how to behave in order to achieve a goal. The reinforcement learning agent and its environment interact over a sequence of discrete time steps. The specification of their interface defines a particular task: the actions are the choices made by the agent; the states are the basis for making the choices; and the rewards are the basis for evaluating the choices. Everything inside the agent is known and controllable. Its environment, on the other hand, is incompletely controllable and may or may not be completely known. A policy is a stochastic rule by which the agent selects actions as a function of states. The agent's objective is to maximize the amount of reward it receives over time."
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        64,
                        420,
                        489,
                        485
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                420,
                                489,
                                485
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        420,
                                        489,
                                        485
                                    ],
                                    "type": "text",
                                    "content": "When the reinforcement learning setup described above is formulated with well defined transition probabilities it constitutes a Markov decision process (MDP). A finite MDP is an MDP with finite state, action, and (as we formulate it here) reward sets. Much of the current theory of reinforcement learning is restricted to finite MDPs, but the methods and ideas apply more generally."
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        64,
                        487,
                        489,
                        592
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                487,
                                489,
                                592
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        487,
                                        489,
                                        592
                                    ],
                                    "type": "text",
                                    "content": "The return is the function of future rewards that the agent seeks to maximize (in expected value). It has several different definitions depending upon the nature of the task and whether one wishes to discount delayed reward. The undiscounted formulation is appropriate for episodic tasks, in which the agent- environment interaction breaks naturally into episodes; the discounted formulation is appropriate for tabular continuing tasks, in which the interaction does not naturally break into episodes but continues without limit (but see Sections 10.3- 4). We try to define the returns for the two kinds of tasks such that one set of equations can apply to both the episodic and continuing cases."
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        64,
                        594,
                        489,
                        726
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                594,
                                489,
                                726
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        594,
                                        489,
                                        726
                                    ],
                                    "type": "text",
                                    "content": "A policy's value functions ( "
                                },
                                {
                                    "bbox": [
                                        64,
                                        594,
                                        489,
                                        726
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        594,
                                        489,
                                        726
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        594,
                                        489,
                                        726
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{\\pi}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        594,
                                        489,
                                        726
                                    ],
                                    "type": "text",
                                    "content": " ) assign to each state, or state- action pair, the expected return from that state, or state- action pair, given that the agent uses the policy. The optimal value functions ( "
                                },
                                {
                                    "bbox": [
                                        64,
                                        594,
                                        489,
                                        726
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        594,
                                        489,
                                        726
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        594,
                                        489,
                                        726
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        594,
                                        489,
                                        726
                                    ],
                                    "type": "text",
                                    "content": " ) assign to each state, or state- action pair, the largest expected return achievable by any policy. A policy whose value functions are optimal is an optimal policy. Whereas the optimal value functions for states and state- action pairs are unique for a given MDP, there can be many optimal policies. Any policy that is greedy with respect to the optimal value functions must be an optimal policy. The Bellman optimality equations are special consistency conditions that the optimal value functions must satisfy and that can, in principle, be solved for the optimal value functions, from which an optimal policy can be determined with relative ease."
                                }
                            ]
                        }
                    ],
                    "index": 5
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 21
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        104,
                        141,
                        530,
                        220
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                141,
                                530,
                                220
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        220
                                    ],
                                    "type": "text",
                                    "content": "A reinforcement learning problem can be posed in a variety of different ways depending on assumptions about the level of knowledge initially available to the agent. In problems of complete knowledge, the agent has a complete and accurate model of the environment's dynamics. If the environment is an MDP, then such a model consists of the complete four- argument dynamics function "
                                },
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        220
                                    ],
                                    "type": "inline_equation",
                                    "content": "p"
                                },
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        220
                                    ],
                                    "type": "text",
                                    "content": " (3.2). In problems of incomplete knowledge, a complete and perfect model of the environment is not available."
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        104,
                        222,
                        530,
                        301
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                222,
                                530,
                                301
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        222,
                                        530,
                                        301
                                    ],
                                    "type": "text",
                                    "content": "Even if the agent had a complete and accurate environment model, the agent would typically be unable to fully use it because of limitations on its memory and computation per time step. In particular, extensive memory may be required to build up accurate approximations of value functions, policies, and models. In most cases of practical interest there are far more states than could possibly be entries in a table, and approximations must be made."
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        104,
                        303,
                        530,
                        368
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                303,
                                530,
                                368
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        303,
                                        530,
                                        368
                                    ],
                                    "type": "text",
                                    "content": "A well- defined notion of optimality organizes the approach to learning we describe in this book and provides a way to understand the theoretical properties of various learning algorithms, but it is an ideal that reinforcement learning agents can only approximate to varying degrees. In reinforcement learning we are very much concerned with cases in which optimal solutions cannot be found but must be approximated in some way."
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        104,
                        389,
                        414,
                        407
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                389,
                                414,
                                407
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        389,
                                        414,
                                        407
                                    ],
                                    "type": "text",
                                    "content": "Bibliographical and Historical Remarks"
                                }
                            ]
                        }
                    ],
                    "index": 3,
                    "level": 1
                },
                {
                    "bbox": [
                        104,
                        418,
                        530,
                        550
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                418,
                                530,
                                550
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        418,
                                        530,
                                        550
                                    ],
                                    "type": "text",
                                    "content": "The reinforcement learning problem is deeply indebted to the idea of Markov decision processes (MDPs) from the field of optimal control. These historical influences and other major influences from psychology are described in the brief history given in Chapter 1. Reinforcement learning adds to MDPs a focus on approximation and incomplete information for realistically large problems. MDPs and the reinforcement learning problem are only weakly linked to traditional learning and decision- making problems in artificial intelligence. However, artificial intelligence is now vigorously exploring MDP formulations for planning and decision making from a variety of perspectives. MDPs are more general than previous formulations used in artificial intelligence in that they permit more general kinds of goals and uncertainty."
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        104,
                        552,
                        530,
                        618
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                552,
                                530,
                                618
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        552,
                                        530,
                                        618
                                    ],
                                    "type": "text",
                                    "content": "The theory of MDPs is treated by, for example, Bertsekas (2005), White (1969), Whittle (1982, 1983), and Puterman (1994). A particularly compact treatment of the finite case is given by Ross (1985). MDPs are also studied under the heading of stochastic optimal control, where adaptive optimal control methods are most closely related to reinforcement learning (e.g., Kumar, 1985; Kumar and Varaiya, 1986)."
                                }
                            ]
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        104,
                        619,
                        530,
                        713
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                619,
                                530,
                                713
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        619,
                                        530,
                                        713
                                    ],
                                    "type": "text",
                                    "content": "The theory of MDPs evolved from efforts to understand the problem of making sequences of decisions under uncertainty, where each decision can depend on the previous decisions and their outcomes. It is sometimes called the theory of multistage decision processes, or sequential decision processes, and has roots in the statistical literature on sequential sampling beginning with the papers by Thompson (1933, 1934) and Robbins (1952) that we cited in Chapter 2 in connection with bandit problems (which are prototypical MDPs if formulated as multiple- situation problems)."
                                }
                            ]
                        }
                    ],
                    "index": 6
                },
                {
                    "bbox": [
                        104,
                        714,
                        530,
                        740
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                714,
                                530,
                                740
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        714,
                                        530,
                                        740
                                    ],
                                    "type": "text",
                                    "content": "The earliest instance (that we are aware of) in which reinforcement learning was discussed using the MDP formalism is Andreae's (1969) description of a unified view of"
                                }
                            ]
                        }
                    ],
                    "index": 7
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 22
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        64,
                        140,
                        489,
                        260
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                140,
                                489,
                                260
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        140,
                                        489,
                                        260
                                    ],
                                    "type": "text",
                                    "content": "learning machines. Witten and Corbin (1973) experimented with a reinforcement learning system later analyzed by Witten (1977, 1976a) using the MDP formalism. Although he did not explicitly mention MDPs, Werbos (1977) suggested approximate solution methods for stochastic optimal control problems that are related to modern reinforcement learning methods (see also Werbos, 1982, 1987, 1988, 1989, 1992). Although Werbos's ideas were not widely recognized at the time, they were prescient in emphasizing the importance of approximately solving optimal control problems in a variety of domains, including artificial intelligence. The most influential integration of reinforcement learning and MDPs is due to Watkins (1989)."
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        64,
                        272,
                        489,
                        392
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                272,
                                489,
                                392
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        272,
                                        489,
                                        392
                                    ],
                                    "type": "text",
                                    "content": "3.1 Our characterization of the dynamics of an MDP in terms of "
                                },
                                {
                                    "bbox": [
                                        64,
                                        272,
                                        489,
                                        392
                                    ],
                                    "type": "inline_equation",
                                    "content": "p(s^{\\prime},r|s,a)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        272,
                                        489,
                                        392
                                    ],
                                    "type": "text",
                                    "content": " is slightly unusual. It is more common in the MDP literature to describe the dynamics in terms of the state transition probabilities "
                                },
                                {
                                    "bbox": [
                                        64,
                                        272,
                                        489,
                                        392
                                    ],
                                    "type": "inline_equation",
                                    "content": "p(s^{\\prime}|s,a)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        272,
                                        489,
                                        392
                                    ],
                                    "type": "text",
                                    "content": " and expected next rewards "
                                },
                                {
                                    "bbox": [
                                        64,
                                        272,
                                        489,
                                        392
                                    ],
                                    "type": "inline_equation",
                                    "content": "r(s,a)"
                                },
                                {
                                    "bbox": [
                                        64,
                                        272,
                                        489,
                                        392
                                    ],
                                    "type": "text",
                                    "content": ". In reinforcement learning, however, we more often have to refer to individual actual or sample rewards (rather than just their expected values). Our notation also makes it plainer that "
                                },
                                {
                                    "bbox": [
                                        64,
                                        272,
                                        489,
                                        392
                                    ],
                                    "type": "inline_equation",
                                    "content": "S_{t}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        272,
                                        489,
                                        392
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        64,
                                        272,
                                        489,
                                        392
                                    ],
                                    "type": "inline_equation",
                                    "content": "R_{t}"
                                },
                                {
                                    "bbox": [
                                        64,
                                        272,
                                        489,
                                        392
                                    ],
                                    "type": "text",
                                    "content": " are in general jointly determined, and thus must have the same time index. In teaching reinforcement learning, we have found our notation to be more straightforward conceptually and easier to understand."
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        104,
                        398,
                        489,
                        425
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                398,
                                489,
                                425
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        398,
                                        489,
                                        425
                                    ],
                                    "type": "text",
                                    "content": "For a good intuitive discussion of the system- theoretic concept of state, see Minsky (1967)."
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        104,
                        430,
                        489,
                        482
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                430,
                                489,
                                482
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        430,
                                        489,
                                        482
                                    ],
                                    "type": "text",
                                    "content": "The bioreactor example is based on the work of Ungar (1990) and Miller and Williams (1992). The recycling robot example was inspired by the can- collecting robot built by Jonathan Connell (1989). Kober and Peters (2012) present a collection of robotics applications of reinforcement learning."
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        64,
                        495,
                        489,
                        522
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                495,
                                489,
                                522
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        495,
                                        489,
                                        522
                                    ],
                                    "type": "text",
                                    "content": "3.2 An explicit statement of the reward hypothesis was suggested by Michael Littman (personal communication)."
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        64,
                        535,
                        489,
                        708
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                64,
                                535,
                                489,
                                708
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        64,
                                        535,
                                        489,
                                        708
                                    ],
                                    "type": "text",
                                    "content": "3.3- 4 The terminology of episodic and continuing tasks is different from that usually used in the MDP literature. In that literature it is common to distinguish three types of tasks: (1) finite- horizon tasks, in which interaction terminates after a particular fixed number of time steps; (2) indefinite- horizon tasks, in which interaction can last arbitrarily long but must eventually terminate; and (3) infinite- horizon tasks, in which interaction does not terminate. Our episodic and continuing tasks are similar to indefinite- horizon and infinite- horizon tasks, respectively, but we prefer to emphasize the difference in the nature of the interaction. This difference seems more fundamental than the difference in the objective functions emphasized by the usual terms. Often episodic tasks use an indefinite- horizon objective function and continuing tasks an infinite- horizon objective function, but we see this as a common coincidence rather than a fundamental difference."
                                }
                            ]
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        104,
                        713,
                        489,
                        740
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                713,
                                489,
                                740
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        713,
                                        489,
                                        740
                                    ],
                                    "type": "text",
                                    "content": "The pole- balancing example is from Michie and Chambers (1968) and Barto, Sutton, and Anderson (1983)."
                                }
                            ]
                        }
                    ],
                    "index": 6
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 23
        },
        {
            "para_blocks": [
                {
                    "bbox": [
                        104,
                        141,
                        530,
                        247
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                104,
                                141,
                                530,
                                247
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        104,
                                        141,
                                        530,
                                        247
                                    ],
                                    "type": "text",
                                    "content": "3.5- 6 Assigning value on the basis of what is good or bad in the long run has ancient roots. In control theory, mapping states to numerical values representing the long- term consequences of control decisions is a key part of optimal control theory, which was developed in the 1950s by extending nineteenth century state- function theories of classical mechanics (see, for example, Schultz and Melsa, 1967). In describing how a computer could be programmed to play chess, Shannon (1950) suggested using an evaluation function that took into account the long- term advantages and disadvantages of chess positions."
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        144,
                        251,
                        530,
                        411
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                144,
                                251,
                                530,
                                411
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        144,
                                        251,
                                        530,
                                        411
                                    ],
                                    "type": "text",
                                    "content": "Watkins's (1989) Q- learning algorithm for estimating "
                                },
                                {
                                    "bbox": [
                                        144,
                                        251,
                                        530,
                                        411
                                    ],
                                    "type": "inline_equation",
                                    "content": "q_{*}"
                                },
                                {
                                    "bbox": [
                                        144,
                                        251,
                                        530,
                                        411
                                    ],
                                    "type": "text",
                                    "content": " (Chapter 6) made action- value functions an important part of reinforcement learning, and consequently these functions are often called \"Q- functions.\" But the idea of an action- value function is much older than this. Shannon (1950) suggested that a function "
                                },
                                {
                                    "bbox": [
                                        144,
                                        251,
                                        530,
                                        411
                                    ],
                                    "type": "inline_equation",
                                    "content": "h(P, M)"
                                },
                                {
                                    "bbox": [
                                        144,
                                        251,
                                        530,
                                        411
                                    ],
                                    "type": "text",
                                    "content": " could be used by a chess- playing program to decide whether a move "
                                },
                                {
                                    "bbox": [
                                        144,
                                        251,
                                        530,
                                        411
                                    ],
                                    "type": "inline_equation",
                                    "content": "M"
                                },
                                {
                                    "bbox": [
                                        144,
                                        251,
                                        530,
                                        411
                                    ],
                                    "type": "text",
                                    "content": " in position "
                                },
                                {
                                    "bbox": [
                                        144,
                                        251,
                                        530,
                                        411
                                    ],
                                    "type": "inline_equation",
                                    "content": "P"
                                },
                                {
                                    "bbox": [
                                        144,
                                        251,
                                        530,
                                        411
                                    ],
                                    "type": "text",
                                    "content": " is worth exploring. Michie's (1961, 1963) MENACE system and Michie and Chambers's (1968) BOXES system can be understood as estimating action- value functions. In classical physics, Hamilton's principal function is an action- value function; Newtonian dynamics are greedy with respect to this function (e.g., Goldstein, 1957). Action- value functions also played a central role in Denardo's (1967) theoretical treatment of dynamic programming in terms of contraction mappings."
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        144,
                        415,
                        530,
                        499
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                144,
                                415,
                                530,
                                499
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        144,
                                        415,
                                        530,
                                        499
                                    ],
                                    "type": "text",
                                    "content": "The Bellman optimality equation (for "
                                },
                                {
                                    "bbox": [
                                        144,
                                        415,
                                        530,
                                        499
                                    ],
                                    "type": "inline_equation",
                                    "content": "v_{*}"
                                },
                                {
                                    "bbox": [
                                        144,
                                        415,
                                        530,
                                        499
                                    ],
                                    "type": "text",
                                    "content": ") was popularized by Richard Bellman (1957a), who called it the \"basic functional equation.\" The counterpart of the Bellman optimality equation for continuous time and state problems is known as the Hamilton- Jacobi- Bellman equation (or often just the Hamilton- Jacobi equation), indicating its roots in classical physics (e.g., Schultz and Melsa, 1967). The golf example was suggested by Chris Watkins."
                                }
                            ]
                        }
                    ],
                    "index": 2
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                595,
                842
            ],
            "page_idx": 24
        }
    ],
    "_backend": "vlm",
    "_version_name": "2.0.6"
}