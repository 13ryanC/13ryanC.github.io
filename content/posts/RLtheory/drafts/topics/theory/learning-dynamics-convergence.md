---
_build:
  render: never
  list: never

date: "2025-07-19"
title: "C. Learning Dynamics & Convergence Theory"
summary: "C. Learning Dynamics & Convergence Theory"
lastmod: "2025-07-19"
category: "Notes"
series: ["RL Topics", "MARL"]
author: "Bryan Chan"
hero: /assets/images/hero3.png
image: /assets/images/card3.png
---


## 3. Learning Theory and Convergence

**Convergence Properties**
- Will a given learning and decision rule, when used by all agents, converge to a solution?
- Has learning really converged? and in what sense?
- Is there an algorithm that converges to equilibrium in every generalâ€‘sum stochastic game?
- Why won't plain gradient ascent just settle?

**Non-Stationarity and Multi-Agent Learning**
- Can agents learn stably while everyone else is also learning? (the non-stationarity problem)
- If each agent just treats the others as part of the environment, what goes wrong?
- Could a single learning rule guarantee 'no regrets' regardless of opponents?

**Learning Framework Definition**
- What game are we actually trying to solve? (which formal game model captures the environment?)
- What experience counts as data? (What goes into our dataset of histories?)
- How are policies updated? (What is the learning algorithm?)
- What counts as success? (What exact learning goal / solution concept are we aiming for?)


# 1 Learning Theory and Convergence

## 1.1 Will a given learning and decision rule, when used by all agents, converge to a solution?

## 1.2 Has learning really converged? and in what sense?

## 1.3 Is there an algorithm that converges to equilibrium in every general-sum stochastic game?

## 1.4 Why won't plain gradient ascent just settle?

# 2 Non-Stationarity and Multi-Agent Learning

## 2.1 Can agents learn stably while everyone else is also learning? (the non-stationarity problem)

## 2.2 If each agent just treats the others as part of the environment, what goes wrong?

## 2.3 Could a single learning rule guarantee 'no regrets' regardless of opponents?

# 3 Learning Framework Definition

## 3.1 What game are we actually trying to solve? (which formal game model captures the environment?)

## 3.2 What experience counts as data? (What goes into our dataset of histories?)

## 3.3 How are policies updated? (What is the learning algorithm?)

## 3.4 What counts as success? (What exact learning goal / solution concept are we aiming for?)















