---
date: "2025-07-19"
title: "Multi-Agent Deep Reinforcement Learning I"
summary: "Multi-Agent Deep Reinforcement Learning I"
lastmod: "2025-07-19"
category: "Notes"
series: ["RL Topics"]
author: "Bryan Chan"
hero: /assets/images/hero3.png
image: /assets/images/card3.png
---


1. **What is the *minimal* agent‑environment interface we can all agree on?**
2. **Should every agent get its *own* neural network, or can they share one?**
3. **When is it worth giving the critic extra information during training?**
4. **How can we break a single team reward into per‑agent signals so each agent can still act greedily?**
5. **When should we use each approach—stacking frames, adding recurrence, or ignoring history altogether?**
6. **How important is the information contained in previous observations to the agents’ decisions?**
7. **Should we standardise rewards/returns?**
8. **Is a single optimiser for all agents really faster (and is it safe)?**
9. **What makes a “fair” learning curve in multi‑agent settings, especially zero‑sum games?**
10. **How do we run a hyper‑parameter search that is both exhaustive *and* comparable across algorithms?**

















